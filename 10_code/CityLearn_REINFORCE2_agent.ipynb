{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CityLearn_REINFORCE2_agent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_OWi-NBKDBU"
      },
      "source": [
        "# CityLearn REINFORCE agent\n",
        "Name: Shota Takeshima"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xXcoRQaXvCz"
      },
      "source": [
        "## Installation: CityLearn\n",
        "\n",
        "* Temporally, I put CityLearn codes in my private git repository to test it. \n",
        "* After some progress is confirmed, I'll push the modified code to our team repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edOW6fSdX_g9",
        "outputId": "0d112062-29d3-4a67-f13b-89ab0f0ab060"
      },
      "source": [
        "!rm -rf ./CityLearn_garage/\n",
        "!git clone https://github.com/shttksm/CityLearn_garage.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CityLearn_garage'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 122 (delta 27), reused 111 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (122/122), 11.92 MiB | 20.14 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QQZwH9x2Y0w"
      },
      "source": [
        "## Confirm the baseline multiple agent, RL_Agents_Coord\n",
        "* RL_Agents_Coord is in `CityLearn_garage/agent.py`. Each building has itw own SAC agent and this class manages such SAC agents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpITDUjVavZE",
        "outputId": "9343414f-14e2-4d9a-bbd5-9d724144b19f"
      },
      "source": [
        "!grep RL_Agents_Coord CityLearn_garage/agent.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class RL_Agents_Coord:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAf3qqa2bO-v"
      },
      "source": [
        "### Simulation environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-FoGj4CbdIG"
      },
      "source": [
        "# Loading libraries\n",
        "import sys\n",
        "sys.path.append(\"./CityLearn_garage\")\n",
        "\n",
        "from citylearn import CityLearn\n",
        "from reward_function import reward_function_ma\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from agent import RL_Agents_Coord\n",
        "\n",
        "import os\n",
        "import gym\n",
        "import numpy as np\n",
        "#from stable_baselines3 import SAC\n",
        "#from stable_baselines3.sac.policies import MlpPolicy as MlpPolicy_SAC\n",
        "#from stable_baselines3.common.callbacks import BaseCallback\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import pickle\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPMFTC5icU0H"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob8ccMUiawB3"
      },
      "source": [
        "def get_env(climate_zone):\n",
        "  # Load environment\n",
        "  data_path = Path(\"./CityLearn_garage/data/Climate_Zone_\"+str(climate_zone))\n",
        "  building_attributes = data_path / 'building_attributes.json'\n",
        "  weather_file = data_path / 'weather_data.csv'\n",
        "  solar_profile = data_path / 'solar_generation_1kW.csv'\n",
        "  building_state_actions = './CityLearn_garage/buildings_state_action_space.json'\n",
        "  # building_ids = [\"Building_1\",\"Building_2\",\"Building_3\",\"Building_4\",\"Building_5\",\"Building_6\",\"Building_7\",\"Building_8\",\"Building_9\"]\n",
        "  building_ids = [\"Building_1\"] # Changed here. From 9 buildings to single building\n",
        "  objective_function = ['ramping','1-load_factor','average_daily_peak','peak_demand','net_electricity_consumption']\n",
        "\n",
        "  # Contain the lower and upper bounds of the states and actions, to be provided to the agent to normalize the variables between 0 and 1.\n",
        "  # Can be obtained using observations_spaces[i].low or .high\n",
        "  env = CityLearn(data_path, \n",
        "                  building_attributes, \n",
        "                  weather_file, \n",
        "                  solar_profile, \n",
        "                  building_ids, \n",
        "                  buildings_states_actions = building_state_actions, \n",
        "                  cost_function = objective_function, \n",
        "                  verbose = 1, \n",
        "                  simulation_period=(0,8760-1), \n",
        "                  central_agent=False)\n",
        "  # Provides information on Building type, Climate Zone, Annual DHW demand, Annual Cooling Demand, Annual Electricity Demand, Solar Capacity, and correllations among buildings\n",
        "  building_info = env.get_building_information()  \n",
        "  observations_spaces, actions_spaces = env.get_state_action_spaces()\n",
        "\n",
        "  return env, building_ids, building_state_actions, building_info, observations_spaces, actions_spaces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUYuMEnAbOHp"
      },
      "source": [
        "env, building_ids, building_state_actions, building_info, observations_spaces, actions_spaces = get_env(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDyZF_4bbXky",
        "outputId": "c8a46006-f585-4726-93ca-663554c90ef3"
      },
      "source": [
        "observations_spaces"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Box(-9.600000381469727, 1090.7900390625, (26,), float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIqsgws-buw7",
        "outputId": "8a581aa7-7ad2-49e6-d9cf-55f49de24698"
      },
      "source": [
        "actions_spaces"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Box(-0.5, 0.5, (2,), float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EVUcfAqbvoX"
      },
      "source": [
        "### Train a instance of RI_Agents_Coord\n",
        "* First in first, I confirm wether the original multiple agents works correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aocmH24bb21Q"
      },
      "source": [
        "# Hyperparameters\n",
        "bs = 256\n",
        "tau = 0.005\n",
        "gamma = 0.99\n",
        "lr = 0.0003\n",
        "hid = [256,256]\n",
        "\n",
        "n_episodes = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7N1oIbob40n"
      },
      "source": [
        "# Instantiating the control agent(s)\n",
        "agents = RL_Agents_Coord(building_ids, \n",
        "                         building_state_actions, \n",
        "                         building_info, \n",
        "                         observations_spaces, \n",
        "                         actions_spaces, \n",
        "                         discount = gamma, \n",
        "                         batch_size = bs, \n",
        "                         replay_buffer_capacity = 1e5, \n",
        "                         regression_buffer_capacity = 12*8760, \n",
        "                         tau=tau, \n",
        "                         lr=lr, \n",
        "                         hidden_dim=hid, \n",
        "                         start_training=8760*3, \n",
        "                         exploration_period = 8760*3+1,  \n",
        "                         start_regression=8760, \n",
        "                         information_sharing = False, \n",
        "                         pca_compression = .95, \n",
        "                         action_scaling_coef=0.5, \n",
        "                         reward_scaling = 5., \n",
        "                         update_per_step = 1, \n",
        "                         iterations_as = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPtvG4TUR68I"
      },
      "source": [
        "**You can skip here**. This cord just confirming the original agents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "8kBA0CDMb7KT",
        "outputId": "78d5d4b3-4f72-4589-8bc1-0e8c9a00383b"
      },
      "source": [
        "cost_by_epoch = []\n",
        "action_hist = []\n",
        "# The number of episodes can be replaces by a stopping criterion (i.e. convergence of the average reward)\n",
        "start = time.time()\n",
        "for e in range(n_episodes): \n",
        "    is_evaluating = (e > 7) # Evaluate deterministic policy after 7 epochs\n",
        "    rewards = []\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    j = 0\n",
        "    action, coordination_vars = agents.select_action(state, deterministic=is_evaluating)   \n",
        "    action_hist.append(action) \n",
        "    while not done:\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        action_next, coordination_vars_next = agents.select_action(next_state, deterministic=is_evaluating)\n",
        "        agents.add_to_buffer(state, action, reward, next_state, done, coordination_vars, coordination_vars_next)\n",
        "        action_hist.append(action_next)\n",
        "        state = next_state\n",
        "        coordination_vars = coordination_vars_next\n",
        "        action = action_next\n",
        "\n",
        "    cost = env.cost()\n",
        "    cost_by_epoch.append(cost)\n",
        "    print('Loss -', cost, 'Simulation time (min) -',(time.time()-start)/60.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cumulated reward: -1673868760.8193188\n",
            "Cost score: {'ramping': 1.776153, '1-load_factor': 1.0796991562924123, 'average_daily_peak': 1.2237937, 'peak_demand': 1.1520804, 'net_electricity_consumption': 1.0314388, 'total': 1.2526330227868028}\n",
            "Loss - {'ramping': 1.776153, '1-load_factor': 1.0796991562924123, 'average_daily_peak': 1.2237937, 'peak_demand': 1.1520804, 'net_electricity_consumption': 1.0314388, 'total': 1.2526330227868028} Simulation time (min) - 0.05038893620173136\n",
            "Cumulated reward: -1659484464.4957087\n",
            "Cost score: {'ramping': 1.7695692, '1-load_factor': 1.0830602986784124, 'average_daily_peak': 1.2179848, 'peak_demand': 1.155436, 'net_electricity_consumption': 1.0302082, 'total': 1.2512517043584852}\n",
            "Loss - {'ramping': 1.7695692, '1-load_factor': 1.0830602986784124, 'average_daily_peak': 1.2179848, 'peak_demand': 1.155436, 'net_electricity_consumption': 1.0302082, 'total': 1.2512517043584852} Simulation time (min) - 0.12334486643473307\n",
            "Cumulated reward: -1660307432.0092876\n",
            "Cost score: {'ramping': 1.760957, '1-load_factor': 1.0881737901652442, 'average_daily_peak': 1.2182944, 'peak_demand': 1.1320208, 'net_electricity_consumption': 1.0309081, 'total': 1.2460708227532027}\n",
            "Loss - {'ramping': 1.760957, '1-load_factor': 1.0881737901652442, 'average_daily_peak': 1.2182944, 'peak_demand': 1.1320208, 'net_electricity_consumption': 1.0309081, 'total': 1.2460708227532027} Simulation time (min) - 0.2802433967590332\n",
            "Cumulated reward: -1358757319.6205413\n",
            "Cost score: {'ramping': 1.2543387, '1-load_factor': 1.028193797570209, 'average_daily_peak': 1.0739751, 'peak_demand': 1.1246986, 'net_electricity_consumption': 1.0124288, 'total': 1.0987270049058875}\n",
            "Loss - {'ramping': 1.2543387, '1-load_factor': 1.028193797570209, 'average_daily_peak': 1.0739751, 'peak_demand': 1.1246986, 'net_electricity_consumption': 1.0124288, 'total': 1.0987270049058875} Simulation time (min) - 2.3210259874661765\n",
            "Cumulated reward: -1163659251.479406\n",
            "Cost score: {'ramping': 1.3403406, '1-load_factor': 1.0242916209689956, 'average_daily_peak': 1.0423335, 'peak_demand': 1.0695517, 'net_electricity_consumption': 1.0008073, 'total': 1.0954649421213503}\n",
            "Loss - {'ramping': 1.3403406, '1-load_factor': 1.0242916209689956, 'average_daily_peak': 1.0423335, 'peak_demand': 1.0695517, 'net_electricity_consumption': 1.0008073, 'total': 1.0954649421213503} Simulation time (min) - 4.345502980550131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b06d95e9ebdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0maction_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordination_vars_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_evaluating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordination_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordination_vars_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0maction_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CityLearn_garage/agent.py\u001b[0m in \u001b[0;36madd_to_buffer\u001b[0;34m(self, states, actions, rewards, next_states, done, coordination_vars, coordination_vars_next)\u001b[0m\n\u001b[1;32m    494\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtarget_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_soft_q_net1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_q_net1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                         target_param.data.copy_(\n\u001b[0;32m--> 496\u001b[0;31m                             \u001b[0mtarget_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m                         )\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JDZkyhh97vP"
      },
      "source": [
        "pd.DataFrame(map(lambda x: x[0], action_hist), columns=[\"cooling_storage\", \"dhw_storage\"])[-8760:-1][\"cooling_storage\"].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KxIponHR_om"
      },
      "source": [
        "ax = pd.DataFrame(cost_by_epoch)[[\"total\"]].plot()\n",
        "cz = env.data_path.name\n",
        "bids = env.building_ids\n",
        "plt.title(f\"Training Curve of SAC multiple-agents (but using only one building)\\n {cz}:{bids}\")\n",
        "plt.xlabel(\"Epoch (1year = 8760hours:timesteps)\")\n",
        "plt.ylabel(\"Total Cost\")\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldyfi_TgcAXR"
      },
      "source": [
        "## Create the baseline RI_ActorCritic_Coord\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXoip-MndFVA"
      },
      "source": [
        "import os\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.distributions import Normal\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.utils as utils\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import gym\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import json\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "import time\n",
        "import math\n",
        "\n",
        "# set the path so that we could read created modules\n",
        "import sys\n",
        "\n",
        "# organized into different classes for editing easier\n",
        "from RBC_Agent import RBC_Agent\n",
        "from model import PolicyNetwork, SoftQNetwork, RegressionBuffer\n",
        "from ReplayBuffer import ReplayBuffer\n",
        "from data_process import no_normalization, periodic_normalization, onehot_encoding, normalize, remove_feature\n",
        "\n",
        "# check cuda is available\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UcdYWk6Tdb-"
      },
      "source": [
        "## Creating REINFORCE agents\n",
        "* MARISA reward, REINFORCE agent for each building, PCA and information shareing are removed.\n",
        "* *Reference*: [pytorch-REINFORCE](https://github.com/chingyaoc/pytorch-REINFORCE)\n",
        "\n",
        "    ![image](https://user-images.githubusercontent.com/56372825/108765699-1d8c3d80-7522-11eb-9c26-508e71c9fe08.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2wAQgOWNaN4"
      },
      "source": [
        "#### Policy network class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toRyRykm9QON"
      },
      "source": [
        "class Policy(nn.Module):\n",
        "    def __init__(self, hidden_size, num_inputs, action_space):\n",
        "        super(Policy, self).__init__()\n",
        "        self.action_space = action_space\n",
        "        num_outputs = action_space.shape[0]\n",
        "\n",
        "        self.linear1 = nn.Linear(num_inputs, hidden_size[0])\n",
        "        self.linear1h = nn.Linear(hidden_size[0], hidden_size[1])\n",
        "        self.linear2 = nn.Linear(hidden_size[1], num_outputs)\n",
        "        self.linear2_ = nn.Linear(hidden_size[1], num_outputs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear1h(x))\n",
        "        mu = F.tanh(self.linear2(x))\n",
        "        sigma_sq = F.tanh(self.linear2_(x))\n",
        "\n",
        "        return mu, sigma_sq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZSwEGsbN4ie"
      },
      "source": [
        "pi = Variable(torch.FloatTensor([math.pi])).cuda()\n",
        "def normal(x, mu, sigma_sq):\n",
        "    a = (-1*(Variable(x)-mu).pow(2)/(2*sigma_sq)).exp()\n",
        "    b = 1/(2*sigma_sq*pi.expand_as(sigma_sq)).sqrt()\n",
        "    return a*b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y69nnzFqNgHz"
      },
      "source": [
        "#### RI_REINFORCE_Agents class\n",
        "\n",
        "* REINFORCE updates Each policy for each buildings \n",
        "* Multiple buildings, MARISA reward, and no information sharing / PCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUamOHae1Ji6"
      },
      "source": [
        "class RI_REINFORCE_Agents():\n",
        "    def __init__(self, building_ids, \n",
        "                 buildings_states_actions, \n",
        "                 building_info,\n",
        "                 observation_spaces = None, \n",
        "                 action_spaces = None):\n",
        "        \n",
        "        # Read valid state variables and action variables for each building\n",
        "        # they are written in buildings_state_action_space.json in CityLean\n",
        "        with open(buildings_states_actions) as json_file:\n",
        "            self.buildings_states_actions = json.load(json_file)\n",
        "\n",
        "        # Set seeds\n",
        "        seed = 20180517 # to init parameters\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # Set action and ovservation spaces for each building\n",
        "        # e.g., 'Building_1' as uid\n",
        "        self.building_ids = building_ids \n",
        "        self.action_spaces = {uid : a_space for uid, a_space in zip(building_ids, action_spaces)}\n",
        "        self.observation_spaces = {uid : o_space for uid, o_space in zip(building_ids, observation_spaces)}\n",
        "\n",
        "        # Set variables for exploration\n",
        "        self.timestep_count = 0\n",
        "        self.epsilon = 0.5\n",
        "    \n",
        "        # Initialize a policy and optimizers\n",
        "        # using empty dict, because keys, building_ids, are str.\n",
        "        self.policies, self.optimizers = {}, {}\n",
        "        for uid in self.building_ids:\n",
        "\n",
        "            # initialize plicy parameters of a policy\n",
        "            hidden_size = [400, 300]\n",
        "            num_inputs = self.observation_spaces[uid].shape[0]\n",
        "\n",
        "            # initialize a policy for a building\n",
        "            self.policies[uid] = Policy(hidden_size, num_inputs, self.action_spaces[uid])\n",
        "            self.policies[uid] = self.policies[uid].cuda()\n",
        "            # initialize a optimizer for a policy\n",
        "            self.optimizers[uid] = optim.Adam(self.policies[uid].parameters(), lr=1e-3)\n",
        "            # set the plicy in training mode\n",
        "            self.policies[uid].train()\n",
        "         \n",
        "    def select_action(self, states):\n",
        "        # update timestep the policies are trained\n",
        "        self.timestep_count += 1\n",
        "        # until three years pass, add (epsilon) * (random noise) into action\n",
        "        self.epsilon = max(0.01, 1.0 - self.timestep_count / (8760*14))\n",
        "        #print(f\"{self.timestep_count}:{self.epsilon}\")\n",
        "\n",
        "        # states is a ndarray, so first chage it as dict of uid\n",
        "        states = {uid : o_space for uid, o_space in zip(self.building_ids, states)}\n",
        "        # initialize actions as dict\n",
        "        actions, log_probs, entropies = {}, {}, {}\n",
        "\n",
        "        # for each policy\n",
        "        for uid in self.building_ids:\n",
        "            # get lower and higher boundary of a building\n",
        "            lowb = self.action_spaces[uid].low\n",
        "            highb = self.action_spaces[uid].high\n",
        "            action_mag = torch.Tensor((highb - lowb) / 2)\n",
        "\n",
        "            # get a state for a bilding and convert it to torch.float32\n",
        "            state = torch.Tensor(states[uid])\n",
        "            mu, sigma_sq = self.policies[uid](Variable(state).cuda())\n",
        "            sigma_sq = F.softplus(sigma_sq)\n",
        "\n",
        "            eps = torch.randn(mu.size())\n",
        "            # calculate the probability\n",
        "            action = action_mag * mu + eps * self.epsilon\n",
        "            #action = (mu + sigma_sq.sqrt()*Variable(eps).cuda()).data\n",
        "\n",
        "            # clip action values in appropriate ranges\n",
        "            for i in range(len(action)):\n",
        "                action[i] = torch.clip(action[i], lowb[i], highb[i])\n",
        "            \n",
        "            prob = normal(action, mu, sigma_sq)\n",
        "\n",
        "            entropy = -0.5*((sigma_sq+2*pi.expand_as(sigma_sq)).log()+1)\n",
        "            log_prob = prob.log()\n",
        "            \n",
        "            actions[uid] = action.detach().cpu().numpy()\n",
        "            entropies[uid] = entropy\n",
        "            log_probs[uid] = log_prob\n",
        "\n",
        "        # changes the type of actions from dict to list of np.ndarray\n",
        "        return list(actions.values()), list(log_probs.values()), list(entropies.values())\n",
        "\n",
        "    def update_policies(self, rewards, log_probs, entropies, gamma):\n",
        "        # for each policy\n",
        "        index = 0\n",
        "        for uid in self.building_ids:\n",
        "            # Dim of rewards is (number of steps) x (number of buildings)\n",
        "            # So take a one reward sequence (step 0 ~ 8759) for one building using uid\n",
        "            f = lambda x: x[index]\n",
        "            reward_one_building = [f(x) for x in rewards]\n",
        "            log_prob_one_building = [f(x) for x in log_probs]\n",
        "            entropy_one_building = [f(x) for x in entropies]\n",
        "            R = torch.zeros(1, )\n",
        "            loss = 0\n",
        "            for i in reversed(range(len(reward_one_building))):\n",
        "                R = gamma * R + reward_one_building[i]\n",
        "                loss = loss - (log_prob_one_building[i]*(Variable(R).expand_as(log_prob_one_building[i])).cuda()).sum() - (0.0001*entropy_one_building[i].cuda()).sum()\n",
        "            loss = loss / len(reward_one_building)\n",
        "\t\t\n",
        "            self.optimizers[uid].zero_grad()\n",
        "            loss.backward()\n",
        "            utils.clip_grad_norm(self.policies[uid].parameters(), 40)\n",
        "            self.optimizers[uid].step()\n",
        "\n",
        "            index += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5LU2D4FNl1k"
      },
      "source": [
        "#### Checking how the REINFORCE agents work correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45w45gv_XLBx",
        "outputId": "e478d41a-7399-4d61-c5c5-3aefd47712d7"
      },
      "source": [
        "torch.Tensor((agent.action_spaces['Building_1'].high - agent.action_spaces['Building_1'].low) / 2)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d7IoCvg_lV5"
      },
      "source": [
        "agent = RI_REINFORCE_Agents(building_ids, \n",
        "                             building_state_actions, \n",
        "                             building_info, \n",
        "                             observations_spaces, \n",
        "                             actions_spaces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY883XRVKPM9",
        "outputId": "b93007d4-7106-43c4-a3a5-e54b47227e32"
      },
      "source": [
        "%%time\n",
        "n_episodes = 14\n",
        "gamma = 0.99\n",
        "\n",
        "costs = []\n",
        "cumulated_rewards = []\n",
        "\n",
        "for i_episode in range(n_episodes):\n",
        "    print(f\"Episode:{i_episode}\")\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    entropies = []\n",
        "    log_probs = []\n",
        "    rewards = []\n",
        "    \n",
        "    while not done:\n",
        "        action, log_prob, entropy = agent.select_action(state)\n",
        "        #print(action)\n",
        "\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        entropies.append(entropy)\n",
        "        log_probs.append(log_prob)\n",
        "        rewards.append(reward)\n",
        "        state = next_state\n",
        "\n",
        "        # every step, update the parameters\n",
        "        agent.update_policies(rewards, log_probs, entropies, gamma)\n",
        "        entropies = []\n",
        "        log_probs = []\n",
        "        rewards = []           \n",
        "        \n",
        "        if done:\n",
        "            costs.append(env.cost())\n",
        "            cumulated_rewards.append(np.sum(rewards))\n",
        "            break\n",
        "    # Here is the first position of update_policies\n",
        "    #agent.update_policies(rewards, log_probs, entropies, gamma)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:0\n",
            "Cumulated reward: -1946800759.7903354\n",
            "Cost score: {'ramping': 2.5004303, '1-load_factor': 1.1347118982591238, 'average_daily_peak': 1.3869452, 'peak_demand': 1.1926126, 'net_electricity_consumption': 1.0275272, 'total': 1.448445470510284}\n",
            "Episode:1\n",
            "Cumulated reward: -1918281110.2072787\n",
            "Cost score: {'ramping': 2.4039733, '1-load_factor': 1.130566044430363, 'average_daily_peak': 1.387516, 'peak_demand': 1.1815301, 'net_electricity_consumption': 1.026934, 'total': 1.4261039105614877}\n",
            "Episode:2\n",
            "Cumulated reward: -1880072961.052394\n",
            "Cost score: {'ramping': 2.312091, '1-load_factor': 1.1324846341231163, 'average_daily_peak': 1.3841088, 'peak_demand': 1.1710763, 'net_electricity_consumption': 1.0275906, 'total': 1.4054702916546404}\n",
            "Episode:3\n",
            "Cumulated reward: -1869409115.2824495\n",
            "Cost score: {'ramping': 2.2709265, '1-load_factor': 1.1364201321060259, 'average_daily_peak': 1.3738109, 'peak_demand': 1.2218697, 'net_electricity_consumption': 1.025396, 'total': 1.4056846382986465}\n",
            "Episode:4\n",
            "Cumulated reward: -1824750871.3184185\n",
            "Cost score: {'ramping': 2.1946466, '1-load_factor': 1.1369476030191006, 'average_daily_peak': 1.3599207, 'peak_demand': 1.1660877, 'net_electricity_consumption': 1.0264262, 'total': 1.376805776554748}\n",
            "Episode:5\n",
            "Cumulated reward: -1803732080.0617197\n",
            "Cost score: {'ramping': 2.032304, '1-load_factor': 1.1316186215009219, 'average_daily_peak': 1.3235514, 'peak_demand': 1.1926126, 'net_electricity_consumption': 1.0247843, 'total': 1.3409742121999646}\n",
            "Episode:6\n",
            "Cumulated reward: -1755507822.8294554\n",
            "Cost score: {'ramping': 1.8921374, '1-load_factor': 1.1217674697278202, 'average_daily_peak': 1.3003579, 'peak_demand': 1.1707038, 'net_electricity_consumption': 1.0243101, 'total': 1.3018553393053662}\n",
            "Episode:7\n",
            "Cumulated reward: -1706412509.3158412\n",
            "Cost score: {'ramping': 1.6555046, '1-load_factor': 1.1043480644053556, 'average_daily_peak': 1.2576678, 'peak_demand': 1.172038, 'net_electricity_consumption': 1.0238311, 'total': 1.2426779033626385}\n",
            "Episode:8\n",
            "Cumulated reward: -1663482242.3740304\n",
            "Cost score: {'ramping': 1.3984805, '1-load_factor': 1.0900005724894921, 'average_daily_peak': 1.1949013, 'peak_demand': 1.1859685, 'net_electricity_consumption': 1.0249859, 'total': 1.178867376384495}\n",
            "Episode:9\n",
            "Cumulated reward: -1626751639.6049876\n",
            "Cost score: {'ramping': 1.1787106, '1-load_factor': 1.0764941376404746, 'average_daily_peak': 1.1400237, 'peak_demand': 1.1281208, 'net_electricity_consumption': 1.0260047, 'total': 1.1098707755795476}\n",
            "Episode:10\n",
            "Cumulated reward: -1608201895.5785267\n",
            "Cost score: {'ramping': 1.0443085, '1-load_factor': 1.0367121727088602, 'average_daily_peak': 1.1005534, 'peak_demand': 1.1246986, 'net_electricity_consumption': 1.0261627, 'total': 1.066487098352502}\n",
            "Episode:11\n",
            "Cumulated reward: -1603752694.638705\n",
            "Cost score: {'ramping': 1.004588, '1-load_factor': 1.029984870742517, 'average_daily_peak': 1.0888493, 'peak_demand': 1.1246986, 'net_electricity_consumption': 1.0262637, 'total': 1.0548769075057423}\n",
            "Episode:12\n",
            "Cumulated reward: -1603864312.1857889\n",
            "Cost score: {'ramping': 1.0018992, '1-load_factor': 1.0278745152898328, 'average_daily_peak': 1.0887691, 'peak_demand': 1.1246986, 'net_electricity_consumption': 1.0262421, 'total': 1.0538967223633864}\n",
            "Episode:13\n",
            "Cumulated reward: -1603863179.970075\n",
            "Cost score: {'ramping': 1.0018169, '1-load_factor': 1.0278745843337915, 'average_daily_peak': 1.0887691, 'peak_demand': 1.1246986, 'net_electricity_consumption': 1.0262419, 'total': 1.0538802137646466}\n",
            "CPU times: user 6min 33s, sys: 6.69 s, total: 6min 40s\n",
            "Wall time: 6min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVeED-6cb2-z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "d31f3a7c-d9bf-4bcc-89cb-e86fa8afc943"
      },
      "source": [
        "ax = pd.DataFrame(costs)[[\"total\"]].plot()\n",
        "cz = env.data_path.name\n",
        "bids = env.building_ids\n",
        "plt.title(f\"Training Curve of REINFORCE multiple-agents (but using only one building)\\n {cz}:{bids}\")\n",
        "plt.xlabel(\"Epoch (1year = 8760hours:timesteps)\")\n",
        "plt.ylabel(\"Total Cost\")\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "playing_with_garage.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_OWi-NBKDBU"
      },
      "source": [
        "# Playing with Garage\n",
        "Name: Shota Takeshima\n",
        "* garage is a toolkit for developing and evaluating reinforcement learning algorithms, and an accompanying library of state-of-the-art implementations built using that toolkit.\n",
        "* I tried to replicate [meta-RL example](https://garage.readthedocs.io/en/latest/user/meta_multi_task_rl_exp.html#) in garage document understanding waht each line in the code means."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHm6rKTDNVYk"
      },
      "source": [
        "## Installation\n",
        "* garage supports python 3.6 or later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az2QIx13NUZk",
        "outputId": "6d9f5cb2-6a34-46b3-f56c-9377e63ce8f4"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S6yn5VlKOjD",
        "outputId": "32683179-a900-425e-efc9-6ccc3cb06271"
      },
      "source": [
        "# install garage\n",
        "!echo \"abcd\" > mujoco_fake_key\n",
        "!rm -rf garage\n",
        "!git clone --depth 1 https://github.com/rlworkgroup/garage/\n",
        "# in this execution of batch script, an error occurs...\n",
        "!cd garage && bash scripts/setup_colab.sh --mjkey ../mujoco_fake_key --no-modify-bashrc > /dev/null!"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'garage'...\n",
            "remote: Enumerating objects: 755, done.\u001b[K\n",
            "remote: Counting objects: 100% (755/755), done.\u001b[K\n",
            "remote: Compressing objects: 100% (663/663), done.\u001b[K\n",
            "remote: Total 755 (delta 203), reused 219 (delta 78), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (755/755), 2.97 MiB | 31.66 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "start of setup_colab.sh\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 88.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "Cloning into '/tmp/tmp.mnEP3VfKQ7/glfw'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 26821 (delta 40), reused 49 (delta 35), pack-reused 26760\u001b[K\n",
            "Receiving objects: 100% (26821/26821), 13.07 MiB | 25.20 MiB/s, done.\n",
            "Resolving deltas: 100% (18914/18914), done.\n",
            "Note: checking out '0be4f3f75aebd9d24583ee86590a38e741db0904'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 0be4f3f7 Add GLFW_FOCUS_ON_SHOW window hint and attribute\n",
            "--2021-02-01 05:49:31--  https://www.roboti.us/download/mujoco200_linux.zip\n",
            "Resolving www.roboti.us (www.roboti.us)... 104.40.85.93\n",
            "Connecting to www.roboti.us (www.roboti.us)|104.40.85.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4427362 (4.2M) [application/zip]\n",
            "Saving to: ‘/tmp/tmp.5hTXJfmDWL/mujoco.zip’\n",
            "\n",
            "/tmp/tmp.5hTXJfmDWL 100%[===================>]   4.22M  4.60MB/s    in 0.9s    \n",
            "\n",
            "2021-02-01 05:49:32 (4.60 MB/s) - ‘/tmp/tmp.5hTXJfmDWL/mujoco.zip’ saved [4427362/4427362]\n",
            "\n",
            "\u001b[33m  WARNING: Missing build requirements in pyproject.toml for mujoco-py<2.1,>=2.0 from https://files.pythonhosted.org/packages/2f/48/b108057c1a23c8da9f4cdc7a7c46ab7cec49c3563c0706d50f2527de6ba0/mujoco-py-2.0.2.13.tar.gz#sha256=d6ae66276b565af9063597fda70683a89c7356290f5ac3961b794ee90ec50eea.\u001b[0m\n",
            "\u001b[33m  WARNING: The project does not specify a build backend, and pip cannot fall back to setuptools without 'wheel'.\u001b[0m\n",
            "  Running command git clone -q git://github.com/deepmind/dm_control.git /tmp/pip-req-build-r8uwm75g\n",
            "  Running command git rev-parse -q --verify 'sha^92f9913013face0468442cd0964d5973ea2089ea'\n",
            "  Running command git fetch -q git://github.com/deepmind/dm_control.git 92f9913013face0468442cd0964d5973ea2089ea\n",
            "  Running command git checkout -q 92f9913013face0468442cd0964d5973ea2089ea\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires coverage==3.7.1, but you have coverage 5.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "coveralls 0.5 requires coverage<3.999,>=3.6, but you have coverage 5.4 which is incompatible.\u001b[0m\n",
            "  Running command git clone -q https://github.com/rlworkgroup/metaworlds.git /tmp/pip-install-h4gbsm9o/metaworlds_2f60bbe24c3b4eba8ff1ed67308561b5\n",
            "  Running command git clone -q https://github.com/rlworkgroup/viskit.git /tmp/pip-install-opmvs_xq/viskit_488479b71f5f471dbbb3b2b5b17b50bb\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cufflinks 0.17.3 requires plotly>=4.1.1, but you have plotly 1.9.6 which is incompatible.\u001b[0m\n",
            "end of setup_colab.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVCsykTbt3s9",
        "outputId": "3288330c-0be6-4d60-9582-d373b59e455a"
      },
      "source": [
        "!garage examples"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-01 05:53:14.755134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "# torch\n",
            "torch/bc_point.py (garage.examples.torch.bc_point)\n",
            "torch/bc_point_deterministic_policy.py (garage.examples.torch.bc_point_deterministic_policy)\n",
            "torch/ddpg_pendulum.py (garage.examples.torch.ddpg_pendulum)\n",
            "torch/dqn_atari.py (garage.examples.torch.dqn_atari)\n",
            "torch/dqn_cartpole.py (garage.examples.torch.dqn_cartpole)\n",
            "torch/maml_ppo_half_cheetah_dir.py (garage.examples.torch.maml_ppo_half_cheetah_dir)\n",
            "torch/maml_trpo_half_cheetah_dir.py (garage.examples.torch.maml_trpo_half_cheetah_dir)\n",
            "torch/maml_trpo_metaworld_ml10.py (garage.examples.torch.maml_trpo_metaworld_ml10)\n",
            "torch/maml_trpo_metaworld_ml1_push.py (garage.examples.torch.maml_trpo_metaworld_ml1_push)\n",
            "torch/maml_trpo_metaworld_ml45.py (garage.examples.torch.maml_trpo_metaworld_ml45)\n",
            "torch/maml_vpg_half_cheetah_dir.py (garage.examples.torch.maml_vpg_half_cheetah_dir)\n",
            "torch/mtppo_metaworld_mt10.py (garage.examples.torch.mtppo_metaworld_mt10)\n",
            "torch/mtppo_metaworld_mt1_push.py (garage.examples.torch.mtppo_metaworld_mt1_push)\n",
            "torch/mtppo_metaworld_mt50.py (garage.examples.torch.mtppo_metaworld_mt50)\n",
            "torch/mtsac_metaworld_mt10.py (garage.examples.torch.mtsac_metaworld_mt10)\n",
            "torch/mtsac_metaworld_mt1_pick_place.py (garage.examples.torch.mtsac_metaworld_mt1_pick_place)\n",
            "torch/mtsac_metaworld_mt50.py (garage.examples.torch.mtsac_metaworld_mt50)\n",
            "torch/mttrpo_metaworld_mt10.py (garage.examples.torch.mttrpo_metaworld_mt10)\n",
            "torch/mttrpo_metaworld_mt1_push.py (garage.examples.torch.mttrpo_metaworld_mt1_push)\n",
            "torch/mttrpo_metaworld_mt50.py (garage.examples.torch.mttrpo_metaworld_mt50)\n",
            "torch/pearl_half_cheetah_vel.py (garage.examples.torch.pearl_half_cheetah_vel)\n",
            "torch/pearl_metaworld_ml10.py (garage.examples.torch.pearl_metaworld_ml10)\n",
            "torch/pearl_metaworld_ml1_push.py (garage.examples.torch.pearl_metaworld_ml1_push)\n",
            "torch/pearl_metaworld_ml45.py (garage.examples.torch.pearl_metaworld_ml45)\n",
            "torch/ppo_pendulum.py (garage.examples.torch.ppo_pendulum)\n",
            "torch/resume_training.py (garage.examples.torch.resume_training)\n",
            "torch/sac_half_cheetah_batch.py (garage.examples.torch.sac_half_cheetah_batch)\n",
            "torch/td3_halfcheetah.py (garage.examples.torch.td3_halfcheetah)\n",
            "torch/td3_pendulum.py (garage.examples.torch.td3_pendulum)\n",
            "torch/trpo_pendulum.py (garage.examples.torch.trpo_pendulum)\n",
            "torch/trpo_pendulum_ray_sampler.py (garage.examples.torch.trpo_pendulum_ray_sampler)\n",
            "torch/tutorial_vpg.py (garage.examples.torch.tutorial_vpg)\n",
            "torch/vpg_pendulum.py (garage.examples.torch.vpg_pendulum)\n",
            "torch/watch_atari.py (garage.examples.torch.watch_atari)\n",
            "\n",
            "# jupyter\n",
            "jupyter/custom_env.ipynb (garage.examples.jupyter.custom_env)\n",
            "jupyter/trpo_gym_tf_cartpole.ipynb (garage.examples.jupyter.trpo_gym_tf_cartpole)\n",
            "\n",
            "# np\n",
            "np/cem_cartpole.py (garage.examples.np.cem_cartpole)\n",
            "np/cma_es_cartpole.py (garage.examples.np.cma_es_cartpole)\n",
            "np/tutorial_cem.py (garage.examples.np.tutorial_cem)\n",
            "\n",
            "# tf\n",
            "tf/ddpg_pendulum.py (garage.examples.tf.ddpg_pendulum)\n",
            "tf/dqn_cartpole.py (garage.examples.tf.dqn_cartpole)\n",
            "tf/dqn_pong.py (garage.examples.tf.dqn_pong)\n",
            "tf/erwr_cartpole.py (garage.examples.tf.erwr_cartpole)\n",
            "tf/her_ddpg_fetchreach.py (garage.examples.tf.her_ddpg_fetchreach)\n",
            "tf/multi_env_ppo.py (garage.examples.tf.multi_env_ppo)\n",
            "tf/multi_env_trpo.py (garage.examples.tf.multi_env_trpo)\n",
            "tf/ppo_memorize_digits.py (garage.examples.tf.ppo_memorize_digits)\n",
            "tf/ppo_pendulum.py (garage.examples.tf.ppo_pendulum)\n",
            "tf/reps_gym_cartpole.py (garage.examples.tf.reps_gym_cartpole)\n",
            "tf/resume_training.py (garage.examples.tf.resume_training)\n",
            "tf/rl2_ppo_halfcheetah.py (garage.examples.tf.rl2_ppo_halfcheetah)\n",
            "tf/rl2_ppo_halfcheetah_meta_test.py (garage.examples.tf.rl2_ppo_halfcheetah_meta_test)\n",
            "tf/rl2_ppo_metaworld_ml10.py (garage.examples.tf.rl2_ppo_metaworld_ml10)\n",
            "tf/rl2_ppo_metaworld_ml1_push.py (garage.examples.tf.rl2_ppo_metaworld_ml1_push)\n",
            "tf/rl2_ppo_metaworld_ml45.py (garage.examples.tf.rl2_ppo_metaworld_ml45)\n",
            "tf/rl2_trpo_halfcheetah.py (garage.examples.tf.rl2_trpo_halfcheetah)\n",
            "tf/td3_pendulum.py (garage.examples.tf.td3_pendulum)\n",
            "tf/te_ppo_metaworld_mt10.py (garage.examples.tf.te_ppo_metaworld_mt10)\n",
            "tf/te_ppo_metaworld_mt1_push.py (garage.examples.tf.te_ppo_metaworld_mt1_push)\n",
            "tf/te_ppo_metaworld_mt50.py (garage.examples.tf.te_ppo_metaworld_mt50)\n",
            "tf/te_ppo_point.py (garage.examples.tf.te_ppo_point)\n",
            "tf/trpo_cartpole.py (garage.examples.tf.trpo_cartpole)\n",
            "tf/trpo_cartpole_bullet.py (garage.examples.tf.trpo_cartpole_bullet)\n",
            "tf/trpo_cartpole_recurrent.py (garage.examples.tf.trpo_cartpole_recurrent)\n",
            "tf/trpo_cubecrash.py (garage.examples.tf.trpo_cubecrash)\n",
            "tf/trpo_gym_tf_cartpole.py (garage.examples.tf.trpo_gym_tf_cartpole)\n",
            "tf/trpo_gym_tf_cartpole_pretrained.py (garage.examples.tf.trpo_gym_tf_cartpole_pretrained)\n",
            "tf/trpo_swimmer.py (garage.examples.tf.trpo_swimmer)\n",
            "tf/trpo_swimmer_ray_sampler.py (garage.examples.tf.trpo_swimmer_ray_sampler)\n",
            "tf/tutorial_vpg.py (garage.examples.tf.tutorial_vpg)\n",
            "tf/vpg_cartpole.py (garage.examples.tf.vpg_cartpole)\n",
            "\n",
            "sim_policy.py (garage.examples.sim_policy)\n",
            "step_bullet_kuka_env.py (garage.examples.step_bullet_kuka_env)\n",
            "step_dm_control_env.py (garage.examples.step_dm_control_env)\n",
            "step_gym_env.py (garage.examples.step_gym_env)\n",
            "[114c94bc9bf0:04047] *** Process received signal ***\n",
            "[114c94bc9bf0:04047] Signal: Segmentation fault (11)\n",
            "[114c94bc9bf0:04047] Signal code: Address not mapped (1)\n",
            "[114c94bc9bf0:04047] Failing at address: 0x7f463103a20d\n",
            "[114c94bc9bf0:04047] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7f4633ce2980]\n",
            "[114c94bc9bf0:04047] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f46339218a5]\n",
            "[114c94bc9bf0:04047] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f463418ce44]\n",
            "[114c94bc9bf0:04047] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f4633922735]\n",
            "[114c94bc9bf0:04047] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f463418acb3]\n",
            "[114c94bc9bf0:04047] *** End of error message ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3w6rtYEP33G"
      },
      "source": [
        "**Restart this notebook here.** it's needed to recognize the installed packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW9uNBfrb9gv"
      },
      "source": [
        "\"\"\"This is an example to train a task with TRPO algorithm.\n",
        "\n",
        "Here it runs CartPole-v1 environment with 100 iterations.\n",
        "\n",
        "Results:\n",
        "    AverageReturn: 100\n",
        "    RiseTime: itr 13\n",
        "\"\"\"\n",
        "from garage import wrap_experiment\n",
        "from garage.envs import GymEnv\n",
        "from garage.experiment.deterministic import set_seed\n",
        "from garage.np.baselines import LinearFeatureBaseline\n",
        "from garage.sampler import LocalSampler\n",
        "from garage.tf.algos import TRPO\n",
        "from garage.tf.policies import CategoricalMLPPolicy\n",
        "from garage.trainer import TFTrainer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2LwIPLvJai2"
      },
      "source": [
        "* Prepare `env`, `policy`, `baseline` which means a value function, `sampler`, `algo` which is an optimizer of policy such as TRPO and MAML, and `trainer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk9AuslPGcfI"
      },
      "source": [
        "@wrap_experiment\n",
        "def trpo_cartpole(ctxt=None, seed=1):\n",
        "    \"\"\"Train TRPO with CartPole-v1 environment.\n",
        "\n",
        "    Args:\n",
        "        ctxt (garage.experiment.ExperimentContext): The experiment\n",
        "            configuration used by Trainer to create the snapshotter.\n",
        "        seed (int): Used to seed the random number generator to produce\n",
        "            determinism.\n",
        "\n",
        "    \"\"\"\n",
        "    set_seed(seed)\n",
        "    with TFTrainer(ctxt) as trainer:\n",
        "        env = GymEnv('CartPole-v1')\n",
        "\n",
        "        policy = CategoricalMLPPolicy(name='policy',\n",
        "                                      env_spec=env.spec,\n",
        "                                      hidden_sizes=(32, 32))\n",
        "\n",
        "        baseline = LinearFeatureBaseline(env_spec=env.spec)\n",
        "\n",
        "        sampler = LocalSampler(agents=policy,\n",
        "                               envs=env,\n",
        "                               max_episode_length=env.spec.max_episode_length,\n",
        "                               is_tf_worker=True)\n",
        "\n",
        "        algo = TRPO(env_spec=env.spec,\n",
        "                    policy=policy,\n",
        "                    baseline=baseline,\n",
        "                    sampler=sampler,\n",
        "                    discount=0.99,\n",
        "                    max_kl_step=0.01)\n",
        "\n",
        "        trainer.setup(algo, env)\n",
        "        trainer.train(n_epochs=100, batch_size=4000)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUcaLoOPbcET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c615cecb-084a-4be4-ce1d-2bd066a2ee1b"
      },
      "source": [
        "trpo_cartpole()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-01 07:04:18 | [trpo_cartpole] Logging to /content/data/local/experiment/trpo_cartpole_1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/garage/src/garage/tf/models/model.py:347: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2021-02-01 07:04:20 | [trpo_cartpole] Obtaining samples...\n",
            "2021-02-01 07:04:29 | [trpo_cartpole] epoch #0 | Optimizing policy...\n",
            "2021-02-01 07:04:29 | [trpo_cartpole] epoch #0 | Computing loss before\n",
            "2021-02-01 07:04:34 | [trpo_cartpole] epoch #0 | Computing KL before\n",
            "2021-02-01 07:04:34 | [trpo_cartpole] epoch #0 | Optimizing\n",
            "2021-02-01 07:04:34 | [trpo_cartpole] epoch #0 | Start CG optimization: #parameters: 1282, #inputs: 195, #subsample_inputs: 195\n",
            "2021-02-01 07:04:34 | [trpo_cartpole] epoch #0 | computing loss before\n",
            "2021-02-01 07:04:34 | [trpo_cartpole] epoch #0 | computing gradient\n",
            "2021-02-01 07:04:34 | [trpo_cartpole] epoch #0 | gradient computed\n",
            "2021-02-01 07:04:34 | [trpo_cartpole] epoch #0 | computing descent direction\n",
            "2021-02-01 07:04:34 | [trpo_cartpole] epoch #0 | descent direction computed\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | backtrack iters: 7\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | optimization finished\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | Computing KL after\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | Computing loss after\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | Fitting baseline...\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | Saving snapshot...\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | Saved\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | Time 14.74 s\n",
            "2021-02-01 07:04:35 | [trpo_cartpole] epoch #0 | EpochTime 14.72 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn         18.4683\n",
            "Evaluation/AverageReturn                   20.7641\n",
            "Evaluation/Iteration                        0\n",
            "Evaluation/MaxReturn                       72\n",
            "Evaluation/MinReturn                        9\n",
            "Evaluation/NumEpisodes                    195\n",
            "Evaluation/StdReturn                        9.74894\n",
            "Evaluation/TerminationRate                  1\n",
            "Extras/EpisodeRewardMean                   21.71\n",
            "LinearFeatureBaseline/ExplainedVariance    -9.81173e-09\n",
            "TotalEnvSteps                            4049\n",
            "policy/Entropy                             16.6386\n",
            "policy/KL                                   0.00183192\n",
            "policy/KLBefore                             0\n",
            "policy/LossAfter                           -0.533388\n",
            "policy/LossBefore                          -0.531048\n",
            "policy/Perplexity                           1.68284e+07\n",
            "policy/dLoss                                0.00234056\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Optimizing policy...\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Computing loss before\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Computing KL before\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Optimizing\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Start CG optimization: #parameters: 1282, #inputs: 207, #subsample_inputs: 207\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | computing loss before\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | computing gradient\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | gradient computed\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | computing descent direction\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | descent direction computed\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | backtrack iters: 6\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | optimization finished\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Computing KL after\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Computing loss after\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Fitting baseline...\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Saving snapshot...\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Saved\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | Time 22.18 s\n",
            "2021-02-01 07:04:42 | [trpo_cartpole] epoch #1 | EpochTime 7.43 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn         17.3064\n",
            "Evaluation/AverageReturn                   19.3768\n",
            "Evaluation/Iteration                        1\n",
            "Evaluation/MaxReturn                       69\n",
            "Evaluation/MinReturn                        8\n",
            "Evaluation/NumEpisodes                    207\n",
            "Evaluation/StdReturn                        9.9556\n",
            "Evaluation/TerminationRate                  1\n",
            "Extras/EpisodeRewardMean                   18.86\n",
            "LinearFeatureBaseline/ExplainedVariance     0.308043\n",
            "TotalEnvSteps                            8060\n",
            "policy/Entropy                             17.6876\n",
            "policy/KL                                   0.00759388\n",
            "policy/KLBefore                             0\n",
            "policy/LossAfter                           -0.0625901\n",
            "policy/LossBefore                           0.00716424\n",
            "policy/Perplexity                           4.80407e+07\n",
            "policy/dLoss                                0.0697543\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | Optimizing policy...\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | Computing loss before\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | Computing KL before\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | Optimizing\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | Start CG optimization: #parameters: 1282, #inputs: 152, #subsample_inputs: 152\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | computing loss before\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | computing gradient\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | gradient computed\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | computing descent direction\n",
            "2021-02-01 07:04:49 | [trpo_cartpole] epoch #2 | descent direction computed\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | backtrack iters: 5\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | optimization finished\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | Computing KL after\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | Computing loss after\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | Fitting baseline...\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | Saving snapshot...\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | Saved\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | Time 29.62 s\n",
            "2021-02-01 07:04:50 | [trpo_cartpole] epoch #2 | EpochTime 7.42 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           22.3819\n",
            "Evaluation/AverageReturn                     26.3487\n",
            "Evaluation/Iteration                          2\n",
            "Evaluation/MaxReturn                         89\n",
            "Evaluation/MinReturn                          9\n",
            "Evaluation/NumEpisodes                      152\n",
            "Evaluation/StdReturn                         15.6134\n",
            "Evaluation/TerminationRate                    1\n",
            "Extras/EpisodeRewardMean                     25.71\n",
            "LinearFeatureBaseline/ExplainedVariance       0.185317\n",
            "TotalEnvSteps                             12065\n",
            "policy/Entropy                               12.617\n",
            "policy/KL                                     0.00858612\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.355995\n",
            "policy/LossBefore                            -0.303688\n",
            "policy/Perplexity                        301649\n",
            "policy/dLoss                                  0.0523073\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Optimizing policy...\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Computing loss before\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Computing KL before\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Optimizing\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Start CG optimization: #parameters: 1282, #inputs: 93, #subsample_inputs: 93\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | computing loss before\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | computing gradient\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | gradient computed\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | computing descent direction\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | descent direction computed\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | backtrack iters: 1\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | optimization finished\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Computing KL after\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Computing loss after\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Fitting baseline...\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Saving snapshot...\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Saved\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | Time 37.00 s\n",
            "2021-02-01 07:04:57 | [trpo_cartpole] epoch #3 | EpochTime 7.37 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          32.395\n",
            "Evaluation/AverageReturn                    43.1613\n",
            "Evaluation/Iteration                         3\n",
            "Evaluation/MaxReturn                       157\n",
            "Evaluation/MinReturn                         9\n",
            "Evaluation/NumEpisodes                      93\n",
            "Evaluation/StdReturn                        30.5277\n",
            "Evaluation/TerminationRate                   1\n",
            "Extras/EpisodeRewardMean                    41.75\n",
            "LinearFeatureBaseline/ExplainedVariance     -1.02007\n",
            "TotalEnvSteps                            16079\n",
            "policy/Entropy                               7.69325\n",
            "policy/KL                                    0.00769381\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.64812\n",
            "policy/LossBefore                           -0.545372\n",
            "policy/Perplexity                         2193.49\n",
            "policy/dLoss                                 0.102748\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Optimizing policy...\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Computing loss before\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Computing KL before\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Optimizing\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Start CG optimization: #parameters: 1282, #inputs: 35, #subsample_inputs: 35\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | computing loss before\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | computing gradient\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | gradient computed\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | computing descent direction\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | descent direction computed\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | backtrack iters: 1\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | optimization finished\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Computing KL after\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Computing loss after\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Fitting baseline...\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Saving snapshot...\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Saved\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | Time 44.41 s\n",
            "2021-02-01 07:05:04 | [trpo_cartpole] epoch #4 | EpochTime 7.40 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          64.9114\n",
            "Evaluation/AverageReturn                   116.057\n",
            "Evaluation/Iteration                         4\n",
            "Evaluation/MaxReturn                       249\n",
            "Evaluation/MinReturn                        27\n",
            "Evaluation/NumEpisodes                      35\n",
            "Evaluation/StdReturn                        50.7464\n",
            "Evaluation/TerminationRate                   1\n",
            "Extras/EpisodeRewardMean                    70.83\n",
            "LinearFeatureBaseline/ExplainedVariance      0.138043\n",
            "TotalEnvSteps                            20141\n",
            "policy/Entropy                               2.79299\n",
            "policy/KL                                    0.00650607\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.232654\n",
            "policy/LossBefore                           -0.181089\n",
            "policy/Perplexity                           16.3298\n",
            "policy/dLoss                                 0.0515651\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Optimizing policy...\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Computing loss before\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Computing KL before\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Optimizing\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Start CG optimization: #parameters: 1282, #inputs: 13, #subsample_inputs: 13\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | computing loss before\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | computing gradient\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | gradient computed\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | computing descent direction\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | descent direction computed\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | backtrack iters: 1\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | optimization finished\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Computing KL after\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Computing loss after\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Fitting baseline...\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Saving snapshot...\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Saved\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | Time 52.36 s\n",
            "2021-02-01 07:05:12 | [trpo_cartpole] epoch #5 | EpochTime 7.94 s\n",
            "---------------------------------------  -------------\n",
            "Evaluation/AverageDiscountedReturn          93.8047\n",
            "Evaluation/AverageReturn                   318.154\n",
            "Evaluation/Iteration                         5\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       161\n",
            "Evaluation/NumEpisodes                      13\n",
            "Evaluation/StdReturn                        96.9662\n",
            "Evaluation/TerminationRate                   0.923077\n",
            "Extras/EpisodeRewardMean                   104.56\n",
            "LinearFeatureBaseline/ExplainedVariance     -0.53093\n",
            "TotalEnvSteps                            24277\n",
            "policy/Entropy                               0.955679\n",
            "policy/KL                                    0.009406\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.138203\n",
            "policy/LossBefore                           -0.116575\n",
            "policy/Perplexity                            2.60044\n",
            "policy/dLoss                                 0.0216275\n",
            "---------------------------------------  -------------\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Optimizing policy...\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Computing loss before\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Computing KL before\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Optimizing\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | computing loss before\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | computing gradient\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | gradient computed\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | computing descent direction\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | descent direction computed\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | backtrack iters: 0\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | optimization finished\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Computing KL after\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Computing loss after\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Fitting baseline...\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Saving snapshot...\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Saved\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | Time 59.98 s\n",
            "2021-02-01 07:05:20 | [trpo_cartpole] epoch #6 | EpochTime 7.61 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          97.6841\n",
            "Evaluation/AverageReturn                   454.778\n",
            "Evaluation/Iteration                         6\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       192\n",
            "Evaluation/NumEpisodes                       9\n",
            "Evaluation/StdReturn                        97.365\n",
            "Evaluation/TerminationRate                   0.333333\n",
            "Extras/EpisodeRewardMean                   141.59\n",
            "LinearFeatureBaseline/ExplainedVariance      0.627083\n",
            "TotalEnvSteps                            28370\n",
            "policy/Entropy                               0.642865\n",
            "policy/KL                                    0.00823679\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.0364905\n",
            "policy/LossBefore                           -0.023269\n",
            "policy/Perplexity                            1.90192\n",
            "policy/dLoss                                 0.0132216\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Optimizing policy...\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Computing loss before\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Computing KL before\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Optimizing\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | computing loss before\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | computing gradient\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | gradient computed\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | computing descent direction\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | descent direction computed\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | backtrack iters: 3\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | optimization finished\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Computing KL after\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Computing loss after\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Fitting baseline...\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Saving snapshot...\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Saved\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | Time 67.06 s\n",
            "2021-02-01 07:05:27 | [trpo_cartpole] epoch #7 | EpochTime 7.07 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          99.343\n",
            "Evaluation/AverageReturn                   500\n",
            "Evaluation/Iteration                         7\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       500\n",
            "Evaluation/NumEpisodes                       8\n",
            "Evaluation/StdReturn                         0\n",
            "Evaluation/TerminationRate                   0\n",
            "Extras/EpisodeRewardMean                   177.74\n",
            "LinearFeatureBaseline/ExplainedVariance      0.988477\n",
            "TotalEnvSteps                            32370\n",
            "policy/Entropy                               0.558396\n",
            "policy/KL                                    0.00645884\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.00648786\n",
            "policy/LossBefore                            3.8147e-09\n",
            "policy/Perplexity                            1.74787\n",
            "policy/dLoss                                 0.00648786\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Optimizing policy...\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Computing loss before\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Computing KL before\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Optimizing\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | computing loss before\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | computing gradient\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | gradient computed\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | computing descent direction\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | descent direction computed\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | backtrack iters: 1\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | optimization finished\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Computing KL after\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Computing loss after\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Fitting baseline...\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Saving snapshot...\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Saved\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | Time 74.33 s\n",
            "2021-02-01 07:05:34 | [trpo_cartpole] epoch #8 | EpochTime 7.27 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn          99.343\n",
            "Evaluation/AverageReturn                   500\n",
            "Evaluation/Iteration                         8\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       500\n",
            "Evaluation/NumEpisodes                       8\n",
            "Evaluation/StdReturn                         0\n",
            "Evaluation/TerminationRate                   0\n",
            "Extras/EpisodeRewardMean                   215.79\n",
            "LinearFeatureBaseline/ExplainedVariance      0.996499\n",
            "TotalEnvSteps                            36370\n",
            "policy/Entropy                               0.586801\n",
            "policy/KL                                    0.00710132\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.0108027\n",
            "policy/LossBefore                            9.53674e-09\n",
            "policy/Perplexity                            1.79823\n",
            "policy/dLoss                                 0.0108027\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Optimizing policy...\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Computing loss before\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Computing KL before\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Optimizing\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | computing loss before\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | computing gradient\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | gradient computed\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | computing descent direction\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | descent direction computed\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | backtrack iters: 0\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | optimization finished\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Computing KL after\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Computing loss after\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Fitting baseline...\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Saving snapshot...\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Saved\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | Time 81.47 s\n",
            "2021-02-01 07:05:41 | [trpo_cartpole] epoch #9 | EpochTime 7.13 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          97.4092\n",
            "Evaluation/AverageReturn                   449.778\n",
            "Evaluation/Iteration                         9\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       181\n",
            "Evaluation/NumEpisodes                       9\n",
            "Evaluation/StdReturn                       103.682\n",
            "Evaluation/TerminationRate                   0.222222\n",
            "Extras/EpisodeRewardMean                   252.27\n",
            "LinearFeatureBaseline/ExplainedVariance      0.723874\n",
            "TotalEnvSteps                            40418\n",
            "policy/Entropy                               0.646225\n",
            "policy/KL                                    0.00835955\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.00457469\n",
            "policy/LossBefore                            0.00255092\n",
            "policy/Perplexity                            1.90832\n",
            "policy/dLoss                                 0.00712562\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Optimizing policy...\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Computing loss before\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Computing KL before\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Optimizing\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | computing loss before\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | computing gradient\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | gradient computed\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | computing descent direction\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | descent direction computed\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | backtrack iters: 1\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | optimization finished\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Computing KL after\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Computing loss after\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Fitting baseline...\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Saving snapshot...\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Saved\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | Time 89.15 s\n",
            "2021-02-01 07:05:49 | [trpo_cartpole] epoch #10 | EpochTime 7.67 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          98.7649\n",
            "Evaluation/AverageReturn                   460\n",
            "Evaluation/Iteration                        10\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       329\n",
            "Evaluation/NumEpisodes                       9\n",
            "Evaluation/StdReturn                        61.4654\n",
            "Evaluation/TerminationRate                   0.333333\n",
            "Extras/EpisodeRewardMean                   289.71\n",
            "LinearFeatureBaseline/ExplainedVariance      0.743596\n",
            "TotalEnvSteps                            44558\n",
            "policy/Entropy                               0.613196\n",
            "policy/KL                                    0.00646835\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.0105259\n",
            "policy/LossBefore                            0.00242029\n",
            "policy/Perplexity                            1.84632\n",
            "policy/dLoss                                 0.0129462\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Optimizing policy...\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Computing loss before\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Computing KL before\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Optimizing\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | computing loss before\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | computing gradient\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | gradient computed\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | computing descent direction\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | descent direction computed\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | backtrack iters: 4\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | optimization finished\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Computing KL after\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Computing loss after\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Fitting baseline...\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Saving snapshot...\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Saved\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | Time 96.92 s\n",
            "2021-02-01 07:05:57 | [trpo_cartpole] epoch #11 | EpochTime 7.76 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn          99.343\n",
            "Evaluation/AverageReturn                   500\n",
            "Evaluation/Iteration                        11\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       500\n",
            "Evaluation/NumEpisodes                       8\n",
            "Evaluation/StdReturn                         0\n",
            "Evaluation/TerminationRate                   0\n",
            "Extras/EpisodeRewardMean                   325.69\n",
            "LinearFeatureBaseline/ExplainedVariance      0.966079\n",
            "TotalEnvSteps                            48558\n",
            "policy/Entropy                               0.550866\n",
            "policy/KL                                    0.00548571\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.0121542\n",
            "policy/LossBefore                           -7.15256e-09\n",
            "policy/Perplexity                            1.73475\n",
            "policy/dLoss                                 0.0121542\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Optimizing policy...\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Computing loss before\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Computing KL before\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Optimizing\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Start CG optimization: #parameters: 1282, #inputs: 13, #subsample_inputs: 13\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | computing loss before\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | computing gradient\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | gradient computed\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | computing descent direction\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | descent direction computed\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | backtrack iters: 1\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | optimization finished\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Computing KL after\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Computing loss after\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Fitting baseline...\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Saving snapshot...\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Saved\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | Time 104.19 s\n",
            "2021-02-01 07:06:04 | [trpo_cartpole] epoch #12 | EpochTime 7.26 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          92.3187\n",
            "Evaluation/AverageReturn                   311.923\n",
            "Evaluation/Iteration                        12\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       136\n",
            "Evaluation/NumEpisodes                      13\n",
            "Evaluation/StdReturn                       119.488\n",
            "Evaluation/TerminationRate                   0.846154\n",
            "Extras/EpisodeRewardMean                   349.7\n",
            "LinearFeatureBaseline/ExplainedVariance      0.200973\n",
            "TotalEnvSteps                            52613\n",
            "policy/Entropy                               0.952513\n",
            "policy/KL                                    0.00861076\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                             0.188686\n",
            "policy/LossBefore                            0.192195\n",
            "policy/Perplexity                            2.59221\n",
            "policy/dLoss                                 0.00350882\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Optimizing policy...\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Computing loss before\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Computing KL before\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Optimizing\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Start CG optimization: #parameters: 1282, #inputs: 19, #subsample_inputs: 19\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | computing loss before\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | computing gradient\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | gradient computed\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | computing descent direction\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | descent direction computed\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | backtrack iters: 1\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | optimization finished\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Computing KL after\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Computing loss after\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Fitting baseline...\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Saving snapshot...\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Saved\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | Time 111.51 s\n",
            "2021-02-01 07:06:11 | [trpo_cartpole] epoch #13 | EpochTime 7.32 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          84.9346\n",
            "Evaluation/AverageReturn                   216.526\n",
            "Evaluation/Iteration                        13\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       118\n",
            "Evaluation/NumEpisodes                      19\n",
            "Evaluation/StdReturn                        91.481\n",
            "Evaluation/TerminationRate                   0.947368\n",
            "Extras/EpisodeRewardMean                   369.92\n",
            "LinearFeatureBaseline/ExplainedVariance      0.470048\n",
            "TotalEnvSteps                            56727\n",
            "policy/Entropy                               1.42589\n",
            "policy/KL                                    0.00730841\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                             0.021765\n",
            "policy/LossBefore                            0.0605731\n",
            "policy/Perplexity                            4.16155\n",
            "policy/dLoss                                 0.0388081\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Optimizing policy...\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Computing loss before\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Computing KL before\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Optimizing\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Start CG optimization: #parameters: 1282, #inputs: 13, #subsample_inputs: 13\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | computing loss before\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | computing gradient\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | gradient computed\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | computing descent direction\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | descent direction computed\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | backtrack iters: 0\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | optimization finished\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Computing KL after\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Computing loss after\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Fitting baseline...\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Saving snapshot...\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Saved\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | Time 118.88 s\n",
            "2021-02-01 07:06:19 | [trpo_cartpole] epoch #14 | EpochTime 7.36 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          86.6068\n",
            "Evaluation/AverageReturn                   311.462\n",
            "Evaluation/Iteration                        14\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                        63\n",
            "Evaluation/NumEpisodes                      13\n",
            "Evaluation/StdReturn                       162.12\n",
            "Evaluation/TerminationRate                   0.769231\n",
            "Extras/EpisodeRewardMean                   378.76\n",
            "LinearFeatureBaseline/ExplainedVariance     -0.0454689\n",
            "TotalEnvSteps                            60776\n",
            "policy/Entropy                               0.928913\n",
            "policy/KL                                    0.00881293\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.0947745\n",
            "policy/LossBefore                           -0.0789518\n",
            "policy/Perplexity                            2.53175\n",
            "policy/dLoss                                 0.0158227\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Optimizing policy...\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Computing loss before\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Computing KL before\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Optimizing\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Start CG optimization: #parameters: 1282, #inputs: 10, #subsample_inputs: 10\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | computing loss before\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | computing gradient\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | gradient computed\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | computing descent direction\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | descent direction computed\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | backtrack iters: 2\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | optimization finished\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Computing KL after\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Computing loss after\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Fitting baseline...\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Saving snapshot...\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Saved\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | Time 126.25 s\n",
            "2021-02-01 07:06:26 | [trpo_cartpole] epoch #15 | EpochTime 7.35 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          97.6586\n",
            "Evaluation/AverageReturn                   415.5\n",
            "Evaluation/Iteration                        15\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       255\n",
            "Evaluation/NumEpisodes                      10\n",
            "Evaluation/StdReturn                        89.255\n",
            "Evaluation/TerminationRate                   0.6\n",
            "Extras/EpisodeRewardMean                   379.67\n",
            "LinearFeatureBaseline/ExplainedVariance      0.711646\n",
            "TotalEnvSteps                            64931\n",
            "policy/Entropy                               0.671204\n",
            "policy/KL                                    0.00715811\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.036663\n",
            "policy/LossBefore                           -0.0159012\n",
            "policy/Perplexity                            1.95659\n",
            "policy/dLoss                                 0.0207618\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Optimizing policy...\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Computing loss before\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Computing KL before\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Optimizing\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Start CG optimization: #parameters: 1282, #inputs: 11, #subsample_inputs: 11\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | computing loss before\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | computing gradient\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | gradient computed\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | computing descent direction\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | descent direction computed\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | backtrack iters: 0\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | optimization finished\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Computing KL after\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Computing loss after\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Fitting baseline...\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Saving snapshot...\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Saved\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | Time 133.92 s\n",
            "2021-02-01 07:06:34 | [trpo_cartpole] epoch #16 | EpochTime 7.66 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          94.0538\n",
            "Evaluation/AverageReturn                   391.818\n",
            "Evaluation/Iteration                        16\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       104\n",
            "Evaluation/NumEpisodes                      11\n",
            "Evaluation/StdReturn                       130.671\n",
            "Evaluation/TerminationRate                   0.636364\n",
            "Extras/EpisodeRewardMean                   368.71\n",
            "LinearFeatureBaseline/ExplainedVariance      0.47454\n",
            "TotalEnvSteps                            69241\n",
            "policy/Entropy                               0.694414\n",
            "policy/KL                                    0.00874183\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.0590498\n",
            "policy/LossBefore                           -0.0494392\n",
            "policy/Perplexity                            2.00253\n",
            "policy/dLoss                                 0.00961055\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Optimizing policy...\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Computing loss before\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Computing KL before\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Optimizing\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Start CG optimization: #parameters: 1282, #inputs: 11, #subsample_inputs: 11\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | computing loss before\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | computing gradient\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | gradient computed\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | computing descent direction\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | descent direction computed\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | backtrack iters: 1\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | optimization finished\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Computing KL after\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Computing loss after\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Fitting baseline...\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Saving snapshot...\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Saved\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | Time 141.27 s\n",
            "2021-02-01 07:06:41 | [trpo_cartpole] epoch #17 | EpochTime 7.34 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          93.1133\n",
            "Evaluation/AverageReturn                   375.273\n",
            "Evaluation/Iteration                        17\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       152\n",
            "Evaluation/NumEpisodes                      11\n",
            "Evaluation/StdReturn                       150.457\n",
            "Evaluation/TerminationRate                   0.454545\n",
            "Extras/EpisodeRewardMean                   358.18\n",
            "LinearFeatureBaseline/ExplainedVariance      0.570604\n",
            "TotalEnvSteps                            73369\n",
            "policy/Entropy                               0.727005\n",
            "policy/KL                                    0.00697655\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.0347543\n",
            "policy/LossBefore                           -0.0245109\n",
            "policy/Perplexity                            2.06888\n",
            "policy/dLoss                                 0.0102434\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Optimizing policy...\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Computing loss before\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Computing KL before\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Optimizing\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | computing loss before\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | computing gradient\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | gradient computed\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | computing descent direction\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | descent direction computed\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | backtrack iters: 1\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | optimization finished\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Computing KL after\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Computing loss after\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Fitting baseline...\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Saving snapshot...\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Saved\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | Time 148.50 s\n",
            "2021-02-01 07:06:48 | [trpo_cartpole] epoch #18 | EpochTime 7.22 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn          99.343\n",
            "Evaluation/AverageReturn                   500\n",
            "Evaluation/Iteration                        18\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       500\n",
            "Evaluation/NumEpisodes                       8\n",
            "Evaluation/StdReturn                         0\n",
            "Evaluation/TerminationRate                   0\n",
            "Extras/EpisodeRewardMean                   359.51\n",
            "LinearFeatureBaseline/ExplainedVariance      0.913953\n",
            "TotalEnvSteps                            77369\n",
            "policy/Entropy                               0.495523\n",
            "policy/KL                                    0.00944342\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.00952171\n",
            "policy/LossBefore                            5.72205e-09\n",
            "policy/Perplexity                            1.64136\n",
            "policy/dLoss                                 0.00952172\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Optimizing policy...\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Computing loss before\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Computing KL before\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Optimizing\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | computing loss before\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | computing gradient\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | gradient computed\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | computing descent direction\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | descent direction computed\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | backtrack iters: 0\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | optimization finished\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Computing KL after\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Computing loss after\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Fitting baseline...\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Saving snapshot...\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Saved\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | Time 156.16 s\n",
            "2021-02-01 07:06:56 | [trpo_cartpole] epoch #19 | EpochTime 7.65 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          99.2064\n",
            "Evaluation/AverageReturn                   486.667\n",
            "Evaluation/Iteration                        19\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       406\n",
            "Evaluation/NumEpisodes                       9\n",
            "Evaluation/StdReturn                        29.6498\n",
            "Evaluation/TerminationRate                   0.222222\n",
            "Extras/EpisodeRewardMean                   361.91\n",
            "LinearFeatureBaseline/ExplainedVariance      0.922018\n",
            "TotalEnvSteps                            81749\n",
            "policy/Entropy                               0.508497\n",
            "policy/KL                                    0.00779253\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                             0.00103566\n",
            "policy/LossBefore                            0.0125645\n",
            "policy/Perplexity                            1.66279\n",
            "policy/dLoss                                 0.0115289\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Optimizing policy...\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Computing loss before\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Computing KL before\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Optimizing\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | computing loss before\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | computing gradient\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | gradient computed\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | computing descent direction\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | descent direction computed\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | backtrack iters: 2\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | optimization finished\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Computing KL after\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Computing loss after\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Fitting baseline...\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Saving snapshot...\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Saved\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | Time 163.24 s\n",
            "2021-02-01 07:07:03 | [trpo_cartpole] epoch #20 | EpochTime 7.07 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn          99.343\n",
            "Evaluation/AverageReturn                   500\n",
            "Evaluation/Iteration                        20\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       500\n",
            "Evaluation/NumEpisodes                       8\n",
            "Evaluation/StdReturn                         0\n",
            "Evaluation/TerminationRate                   0\n",
            "Extras/EpisodeRewardMean                   367.38\n",
            "LinearFeatureBaseline/ExplainedVariance      0.986358\n",
            "TotalEnvSteps                            85749\n",
            "policy/Entropy                               0.532056\n",
            "policy/KL                                    0.00851633\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.00111884\n",
            "policy/LossBefore                           -1.90735e-09\n",
            "policy/Perplexity                            1.70243\n",
            "policy/dLoss                                 0.00111884\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Optimizing policy...\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Computing loss before\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Computing KL before\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Optimizing\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | computing loss before\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | computing gradient\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | gradient computed\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | computing descent direction\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | descent direction computed\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | backtrack iters: 1\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | optimization finished\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Computing KL after\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Computing loss after\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Fitting baseline...\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Saving snapshot...\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Saved\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | Time 171.26 s\n",
            "2021-02-01 07:07:11 | [trpo_cartpole] epoch #21 | EpochTime 8.02 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          99.1135\n",
            "Evaluation/AverageReturn                   482.222\n",
            "Evaluation/Iteration                        21\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       366\n",
            "Evaluation/NumEpisodes                       9\n",
            "Evaluation/StdReturn                        41.8828\n",
            "Evaluation/TerminationRate                   0.222222\n",
            "Extras/EpisodeRewardMean                   379.73\n",
            "LinearFeatureBaseline/ExplainedVariance      0.896983\n",
            "TotalEnvSteps                            90089\n",
            "policy/Entropy                               0.535465\n",
            "policy/KL                                    0.0065901\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.00142925\n",
            "policy/LossBefore                            0.00876655\n",
            "policy/Perplexity                            1.70824\n",
            "policy/dLoss                                 0.0101958\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Optimizing policy...\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Computing loss before\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Computing KL before\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Optimizing\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | computing loss before\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | computing gradient\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | gradient computed\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | computing descent direction\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | descent direction computed\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | backtrack iters: 0\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | optimization finished\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Computing KL after\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Computing loss after\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Fitting baseline...\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Saving snapshot...\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Saved\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | Time 179.05 s\n",
            "2021-02-01 07:07:19 | [trpo_cartpole] epoch #22 | EpochTime 7.78 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          99.0849\n",
            "Evaluation/AverageReturn                   479.778\n",
            "Evaluation/Iteration                        22\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       363\n",
            "Evaluation/NumEpisodes                       9\n",
            "Evaluation/StdReturn                        43.6063\n",
            "Evaluation/TerminationRate                   0.222222\n",
            "Extras/EpisodeRewardMean                   405.61\n",
            "LinearFeatureBaseline/ExplainedVariance      0.939017\n",
            "TotalEnvSteps                            94407\n",
            "policy/Entropy                               0.516771\n",
            "policy/KL                                    0.00916421\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.00325492\n",
            "policy/LossBefore                            0.00522249\n",
            "policy/Perplexity                            1.67661\n",
            "policy/dLoss                                 0.00847742\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | Optimizing policy...\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | Computing loss before\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | Computing KL before\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | Optimizing\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | computing loss before\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | computing gradient\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | gradient computed\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | computing descent direction\n",
            "2021-02-01 07:07:26 | [trpo_cartpole] epoch #23 | descent direction computed\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | backtrack iters: 1\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | optimization finished\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | Computing KL after\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | Computing loss after\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | Fitting baseline...\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | Saving snapshot...\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | Saved\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | Time 186.56 s\n",
            "2021-02-01 07:07:27 | [trpo_cartpole] epoch #23 | EpochTime 7.51 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn          98.933\n",
            "Evaluation/AverageReturn                   471.667\n",
            "Evaluation/Iteration                        23\n",
            "Evaluation/MaxReturn                       500\n",
            "Evaluation/MinReturn                       339\n",
            "Evaluation/NumEpisodes                       9\n",
            "Evaluation/StdReturn                        55.3092\n",
            "Evaluation/TerminationRate                   0.222222\n",
            "Extras/EpisodeRewardMean                   429.09\n",
            "LinearFeatureBaseline/ExplainedVariance      0.875283\n",
            "TotalEnvSteps                            98652\n",
            "policy/Entropy                               0.535861\n",
            "policy/KL                                    0.00629693\n",
            "policy/KLBefore                              0\n",
            "policy/LossAfter                            -0.0142101\n",
            "policy/LossBefore                           -0.0124436\n",
            "policy/Perplexity                            1.70892\n",
            "policy/dLoss                                 0.00176652\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Optimizing policy...\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Computing loss before\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Computing KL before\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Optimizing\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | computing loss before\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | computing gradient\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | gradient computed\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | computing descent direction\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | descent direction computed\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | backtrack iters: 1\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | optimization finished\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Computing KL after\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Computing loss after\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Fitting baseline...\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Saving snapshot...\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Saved\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | Time 194.35 s\n",
            "2021-02-01 07:07:34 | [trpo_cartpole] epoch #24 | EpochTime 7.78 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.2319\n",
            "Evaluation/AverageReturn                    489.778\n",
            "Evaluation/Iteration                         24\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        408\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                         28.9128\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    443.4\n",
            "LinearFeatureBaseline/ExplainedVariance       0.94892\n",
            "TotalEnvSteps                            103060\n",
            "policy/Entropy                                0.502581\n",
            "policy/KL                                     0.0077546\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.000673896\n",
            "policy/LossBefore                             0.0115503\n",
            "policy/Perplexity                             1.65298\n",
            "policy/dLoss                                  0.0108764\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | Optimizing policy...\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | Computing loss before\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | Computing KL before\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | Optimizing\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | computing loss before\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | computing gradient\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | gradient computed\n",
            "2021-02-01 07:07:42 | [trpo_cartpole] epoch #25 | computing descent direction\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | descent direction computed\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | backtrack iters: 0\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | optimization finished\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | Computing KL after\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | Computing loss after\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | Fitting baseline...\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | Saving snapshot...\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | Saved\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | Time 202.59 s\n",
            "2021-02-01 07:07:43 | [trpo_cartpole] epoch #25 | EpochTime 8.24 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.3267\n",
            "Evaluation/AverageReturn                    497.778\n",
            "Evaluation/Iteration                         25\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        480\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                          6.28539\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    460.83\n",
            "LinearFeatureBaseline/ExplainedVariance       0.947808\n",
            "TotalEnvSteps                            107540\n",
            "policy/Entropy                                0.491608\n",
            "policy/KL                                     0.00442918\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00515442\n",
            "policy/LossBefore                             0.00240166\n",
            "policy/Perplexity                             1.63494\n",
            "policy/dLoss                                  0.00755608\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Optimizing policy...\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Computing loss before\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Computing KL before\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Optimizing\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | computing loss before\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | computing gradient\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | gradient computed\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | computing descent direction\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | descent direction computed\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | backtrack iters: 2\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | optimization finished\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Computing KL after\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Computing loss after\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Fitting baseline...\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Saving snapshot...\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Saved\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | Time 209.67 s\n",
            "2021-02-01 07:07:50 | [trpo_cartpole] epoch #26 | EpochTime 7.06 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         26\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    466.09\n",
            "LinearFeatureBaseline/ExplainedVariance       0.99521\n",
            "TotalEnvSteps                            111540\n",
            "policy/Entropy                                0.466576\n",
            "policy/KL                                     0.00943713\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.000240492\n",
            "policy/LossBefore                            -7.86781e-09\n",
            "policy/Perplexity                             1.59452\n",
            "policy/dLoss                                  0.000240484\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Optimizing policy...\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Computing loss before\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Computing KL before\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Optimizing\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | computing loss before\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | computing gradient\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | gradient computed\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | computing descent direction\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | descent direction computed\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | backtrack iters: 2\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | optimization finished\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Computing KL after\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Computing loss after\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Fitting baseline...\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Saving snapshot...\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Saved\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | Time 216.90 s\n",
            "2021-02-01 07:07:57 | [trpo_cartpole] epoch #27 | EpochTime 7.23 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         27\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    473.68\n",
            "LinearFeatureBaseline/ExplainedVariance       0.996536\n",
            "TotalEnvSteps                            115540\n",
            "policy/Entropy                                0.469045\n",
            "policy/KL                                     0.00587927\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00908766\n",
            "policy/LossBefore                             9.53674e-10\n",
            "policy/Perplexity                             1.59847\n",
            "policy/dLoss                                  0.00908767\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Optimizing policy...\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Computing loss before\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Computing KL before\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Optimizing\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | computing loss before\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | computing gradient\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | gradient computed\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | computing descent direction\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | descent direction computed\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | backtrack iters: 0\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | optimization finished\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Computing KL after\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Computing loss after\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Fitting baseline...\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Saving snapshot...\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Saved\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | Time 224.01 s\n",
            "2021-02-01 07:08:04 | [trpo_cartpole] epoch #28 | EpochTime 7.09 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         28\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    483.65\n",
            "LinearFeatureBaseline/ExplainedVariance       0.99638\n",
            "TotalEnvSteps                            119540\n",
            "policy/Entropy                                0.508694\n",
            "policy/KL                                     0.00913651\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0100112\n",
            "policy/LossBefore                            -3.8147e-09\n",
            "policy/Perplexity                             1.66312\n",
            "policy/dLoss                                  0.0100112\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Optimizing policy...\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Computing loss before\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Computing KL before\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Optimizing\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | computing loss before\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | computing gradient\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | gradient computed\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | computing descent direction\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | descent direction computed\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | backtrack iters: 1\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | optimization finished\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Computing KL after\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Computing loss after\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Fitting baseline...\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Saving snapshot...\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Saved\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | Time 231.16 s\n",
            "2021-02-01 07:08:11 | [trpo_cartpole] epoch #29 | EpochTime 7.14 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         29\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    491.71\n",
            "LinearFeatureBaseline/ExplainedVariance       0.988595\n",
            "TotalEnvSteps                            123540\n",
            "policy/Entropy                                0.483775\n",
            "policy/KL                                     0.00837315\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0143961\n",
            "policy/LossBefore                            -3.8147e-09\n",
            "policy/Perplexity                             1.62219\n",
            "policy/dLoss                                  0.0143961\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Optimizing policy...\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Computing loss before\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Computing KL before\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Optimizing\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | computing loss before\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | computing gradient\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | gradient computed\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | computing descent direction\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | descent direction computed\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | backtrack iters: 2\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | optimization finished\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Computing KL after\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Computing loss after\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Fitting baseline...\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Saving snapshot...\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Saved\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | Time 238.33 s\n",
            "2021-02-01 07:08:18 | [trpo_cartpole] epoch #30 | EpochTime 7.16 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         30\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    491.71\n",
            "LinearFeatureBaseline/ExplainedVariance       0.99665\n",
            "TotalEnvSteps                            127540\n",
            "policy/Entropy                                0.507157\n",
            "policy/KL                                     0.00627462\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0063261\n",
            "policy/LossBefore                             3.8147e-09\n",
            "policy/Perplexity                             1.66056\n",
            "policy/dLoss                                  0.00632611\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Optimizing policy...\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Computing loss before\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Computing KL before\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Optimizing\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | computing loss before\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | computing gradient\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | gradient computed\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | computing descent direction\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | descent direction computed\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | backtrack iters: 1\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | optimization finished\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Computing KL after\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Computing loss after\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Fitting baseline...\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Saving snapshot...\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Saved\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | Time 245.68 s\n",
            "2021-02-01 07:08:26 | [trpo_cartpole] epoch #31 | EpochTime 7.34 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           98.848\n",
            "Evaluation/AverageReturn                    462\n",
            "Evaluation/Iteration                         31\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        355\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                         55.9702\n",
            "Evaluation/TerminationRate                    0.333333\n",
            "Extras/EpisodeRewardMean                    489.49\n",
            "LinearFeatureBaseline/ExplainedVariance       0.78554\n",
            "TotalEnvSteps                            131698\n",
            "policy/Entropy                                0.569121\n",
            "policy/KL                                     0.00760842\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0438803\n",
            "policy/LossBefore                            -0.0362211\n",
            "policy/Perplexity                             1.76671\n",
            "policy/dLoss                                  0.00765915\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Optimizing policy...\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Computing loss before\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Computing KL before\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Optimizing\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Start CG optimization: #parameters: 1282, #inputs: 11, #subsample_inputs: 11\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | computing loss before\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | computing gradient\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | gradient computed\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | computing descent direction\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | descent direction computed\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | backtrack iters: 1\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | optimization finished\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Computing KL after\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Computing loss after\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Fitting baseline...\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Saving snapshot...\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Saved\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | Time 252.83 s\n",
            "2021-02-01 07:08:33 | [trpo_cartpole] epoch #32 | EpochTime 7.14 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           93.4399\n",
            "Evaluation/AverageReturn                    364.636\n",
            "Evaluation/Iteration                         32\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        151\n",
            "Evaluation/NumEpisodes                       11\n",
            "Evaluation/StdReturn                        137.791\n",
            "Evaluation/TerminationRate                    0.727273\n",
            "Extras/EpisodeRewardMean                    476.2\n",
            "LinearFeatureBaseline/ExplainedVariance       0.629567\n",
            "TotalEnvSteps                            135709\n",
            "policy/Entropy                                0.771953\n",
            "policy/KL                                     0.00921713\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.0775096\n",
            "policy/LossBefore                             0.0912547\n",
            "policy/Perplexity                             2.16399\n",
            "policy/dLoss                                  0.0137451\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Optimizing policy...\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Computing loss before\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Computing KL before\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Optimizing\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Start CG optimization: #parameters: 1282, #inputs: 11, #subsample_inputs: 11\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | computing loss before\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | computing gradient\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | gradient computed\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | computing descent direction\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | descent direction computed\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | backtrack iters: 2\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | optimization finished\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Computing KL after\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Computing loss after\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Fitting baseline...\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Saving snapshot...\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Saved\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | Time 259.94 s\n",
            "2021-02-01 07:08:40 | [trpo_cartpole] epoch #33 | EpochTime 7.10 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           92.4557\n",
            "Evaluation/AverageReturn                    365.455\n",
            "Evaluation/Iteration                         33\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        135\n",
            "Evaluation/NumEpisodes                       11\n",
            "Evaluation/StdReturn                        152.482\n",
            "Evaluation/TerminationRate                    0.636364\n",
            "Extras/EpisodeRewardMean                    461.85\n",
            "LinearFeatureBaseline/ExplainedVariance      -0.752937\n",
            "TotalEnvSteps                            139729\n",
            "policy/Entropy                                0.759944\n",
            "policy/KL                                     0.00633061\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.00692784\n",
            "policy/LossBefore                             0.0205139\n",
            "policy/Perplexity                             2.13816\n",
            "policy/dLoss                                  0.0135861\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Optimizing policy...\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Computing loss before\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Computing KL before\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Optimizing\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Start CG optimization: #parameters: 1282, #inputs: 15, #subsample_inputs: 15\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | computing loss before\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | computing gradient\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | gradient computed\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | computing descent direction\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | descent direction computed\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | backtrack iters: 1\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | optimization finished\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Computing KL after\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Computing loss after\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Fitting baseline...\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Saving snapshot...\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Saved\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | Time 267.70 s\n",
            "2021-02-01 07:08:48 | [trpo_cartpole] epoch #34 | EpochTime 7.75 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           87.9515\n",
            "Evaluation/AverageReturn                    291.067\n",
            "Evaluation/Iteration                         34\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        115\n",
            "Evaluation/NumEpisodes                       15\n",
            "Evaluation/StdReturn                        151.585\n",
            "Evaluation/TerminationRate                    0.733333\n",
            "Extras/EpisodeRewardMean                    434.43\n",
            "LinearFeatureBaseline/ExplainedVariance       0.643137\n",
            "TotalEnvSteps                            144095\n",
            "policy/Entropy                                0.998706\n",
            "policy/KL                                     0.00969822\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.129493\n",
            "policy/LossBefore                             0.138941\n",
            "policy/Perplexity                             2.71477\n",
            "policy/dLoss                                  0.00944845\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Optimizing policy...\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Computing loss before\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Computing KL before\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Optimizing\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Start CG optimization: #parameters: 1282, #inputs: 10, #subsample_inputs: 10\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | computing loss before\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | computing gradient\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | gradient computed\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | computing descent direction\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | descent direction computed\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | backtrack iters: 2\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | optimization finished\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Computing KL after\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Computing loss after\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Fitting baseline...\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Saving snapshot...\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Saved\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | Time 274.97 s\n",
            "2021-02-01 07:08:55 | [trpo_cartpole] epoch #35 | EpochTime 7.26 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           93.8894\n",
            "Evaluation/AverageReturn                    402.5\n",
            "Evaluation/Iteration                         35\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        126\n",
            "Evaluation/NumEpisodes                       10\n",
            "Evaluation/StdReturn                        142.329\n",
            "Evaluation/TerminationRate                    0.5\n",
            "Extras/EpisodeRewardMean                    425.6\n",
            "LinearFeatureBaseline/ExplainedVariance      -0.531447\n",
            "TotalEnvSteps                            148120\n",
            "policy/Entropy                                0.661676\n",
            "policy/KL                                     0.00689889\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0592252\n",
            "policy/LossBefore                            -0.0461159\n",
            "policy/Perplexity                             1.93804\n",
            "policy/dLoss                                  0.0131093\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Optimizing policy...\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Computing loss before\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Computing KL before\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Optimizing\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Start CG optimization: #parameters: 1282, #inputs: 16, #subsample_inputs: 16\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | computing loss before\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | computing gradient\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | gradient computed\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | computing descent direction\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | descent direction computed\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | backtrack iters: 1\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | optimization finished\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Computing KL after\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Computing loss after\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Fitting baseline...\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Saving snapshot...\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Saved\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | Time 282.37 s\n",
            "2021-02-01 07:09:02 | [trpo_cartpole] epoch #36 | EpochTime 7.39 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           90.3585\n",
            "Evaluation/AverageReturn                    262.688\n",
            "Evaluation/Iteration                         36\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        175\n",
            "Evaluation/NumEpisodes                       16\n",
            "Evaluation/StdReturn                         94.3562\n",
            "Evaluation/TerminationRate                    0.9375\n",
            "Extras/EpisodeRewardMean                    387.83\n",
            "LinearFeatureBaseline/ExplainedVariance       0.780581\n",
            "TotalEnvSteps                            152323\n",
            "policy/Entropy                                1.13244\n",
            "policy/KL                                     0.00728784\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.0720472\n",
            "policy/LossBefore                             0.0926382\n",
            "policy/Perplexity                             3.10323\n",
            "policy/dLoss                                  0.0205909\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Optimizing policy...\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Computing loss before\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Computing KL before\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Optimizing\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Start CG optimization: #parameters: 1282, #inputs: 10, #subsample_inputs: 10\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | computing loss before\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | computing gradient\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | gradient computed\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | computing descent direction\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | descent direction computed\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | backtrack iters: 1\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | optimization finished\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Computing KL after\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Computing loss after\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Fitting baseline...\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Saving snapshot...\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Saved\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | Time 290.09 s\n",
            "2021-02-01 07:09:10 | [trpo_cartpole] epoch #37 | EpochTime 7.71 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           97.6326\n",
            "Evaluation/AverageReturn                    423.2\n",
            "Evaluation/Iteration                         37\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        232\n",
            "Evaluation/NumEpisodes                       10\n",
            "Evaluation/StdReturn                         93.6288\n",
            "Evaluation/TerminationRate                    0.5\n",
            "Extras/EpisodeRewardMean                    380.15\n",
            "LinearFeatureBaseline/ExplainedVariance       0.755867\n",
            "TotalEnvSteps                            156555\n",
            "policy/Entropy                                0.629299\n",
            "policy/KL                                     0.00640374\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0906933\n",
            "policy/LossBefore                            -0.0706887\n",
            "policy/Perplexity                             1.87629\n",
            "policy/dLoss                                  0.0200046\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Optimizing policy...\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Computing loss before\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Computing KL before\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Optimizing\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Start CG optimization: #parameters: 1282, #inputs: 11, #subsample_inputs: 11\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | computing loss before\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | computing gradient\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | gradient computed\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | computing descent direction\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | descent direction computed\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | backtrack iters: 1\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | optimization finished\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Computing KL after\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Computing loss after\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Fitting baseline...\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Saving snapshot...\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Saved\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | Time 297.51 s\n",
            "2021-02-01 07:09:17 | [trpo_cartpole] epoch #38 | EpochTime 7.40 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           95.6644\n",
            "Evaluation/AverageReturn                    369.091\n",
            "Evaluation/Iteration                         38\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        212\n",
            "Evaluation/NumEpisodes                       11\n",
            "Evaluation/StdReturn                        116.388\n",
            "Evaluation/TerminationRate                    0.636364\n",
            "Extras/EpisodeRewardMean                    365.75\n",
            "LinearFeatureBaseline/ExplainedVariance       0.0758739\n",
            "TotalEnvSteps                            160615\n",
            "policy/Entropy                                0.769808\n",
            "policy/KL                                     0.00886563\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.0745137\n",
            "policy/LossBefore                             0.0924667\n",
            "policy/Perplexity                             2.15935\n",
            "policy/dLoss                                  0.0179531\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Optimizing policy...\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Computing loss before\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Computing KL before\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Optimizing\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Start CG optimization: #parameters: 1282, #inputs: 10, #subsample_inputs: 10\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | computing loss before\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | computing gradient\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | gradient computed\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | computing descent direction\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | descent direction computed\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | backtrack iters: 1\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | optimization finished\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Computing KL after\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Computing loss after\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Fitting baseline...\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Saving snapshot...\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Saved\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | Time 305.15 s\n",
            "2021-02-01 07:09:25 | [trpo_cartpole] epoch #39 | EpochTime 7.64 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           97.7275\n",
            "Evaluation/AverageReturn                    420.3\n",
            "Evaluation/Iteration                         39\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        246\n",
            "Evaluation/NumEpisodes                       10\n",
            "Evaluation/StdReturn                         88.7413\n",
            "Evaluation/TerminationRate                    0.6\n",
            "Extras/EpisodeRewardMean                    357.78\n",
            "LinearFeatureBaseline/ExplainedVariance       0.676095\n",
            "TotalEnvSteps                            164818\n",
            "policy/Entropy                                0.670165\n",
            "policy/KL                                     0.00799006\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.132252\n",
            "policy/LossBefore                            -0.113702\n",
            "policy/Perplexity                             1.95456\n",
            "policy/dLoss                                  0.0185503\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Optimizing policy...\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Computing loss before\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Computing KL before\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Optimizing\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Start CG optimization: #parameters: 1282, #inputs: 11, #subsample_inputs: 11\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | computing loss before\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | computing gradient\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | gradient computed\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | computing descent direction\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | descent direction computed\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | backtrack iters: 0\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | optimization finished\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Computing KL after\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Computing loss after\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Fitting baseline...\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Saving snapshot...\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Saved\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | Time 313.19 s\n",
            "2021-02-01 07:09:33 | [trpo_cartpole] epoch #40 | EpochTime 8.03 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           95.9277\n",
            "Evaluation/AverageReturn                    408.455\n",
            "Evaluation/Iteration                         40\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        172\n",
            "Evaluation/NumEpisodes                       11\n",
            "Evaluation/StdReturn                        127.85\n",
            "Evaluation/TerminationRate                    0.363636\n",
            "Extras/EpisodeRewardMean                    355.9\n",
            "LinearFeatureBaseline/ExplainedVariance       0.722185\n",
            "TotalEnvSteps                            169311\n",
            "policy/Entropy                                0.670886\n",
            "policy/KL                                     0.00852947\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00591741\n",
            "policy/LossBefore                             0.0206963\n",
            "policy/Perplexity                             1.95597\n",
            "policy/dLoss                                  0.0266137\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Optimizing policy...\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Computing loss before\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Computing KL before\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Optimizing\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | computing loss before\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | computing gradient\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | gradient computed\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | computing descent direction\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | descent direction computed\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | backtrack iters: 0\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | optimization finished\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Computing KL after\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Computing loss after\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Fitting baseline...\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Saving snapshot...\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Saved\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | Time 321.34 s\n",
            "2021-02-01 07:09:41 | [trpo_cartpole] epoch #41 | EpochTime 8.14 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.1324\n",
            "Evaluation/AverageReturn                    485\n",
            "Evaluation/Iteration                         41\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        365\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                         42.4264\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    368.32\n",
            "LinearFeatureBaseline/ExplainedVariance       0.662384\n",
            "TotalEnvSteps                            173676\n",
            "policy/Entropy                                0.543511\n",
            "policy/KL                                     0.00459986\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0187966\n",
            "policy/LossBefore                            -0.00990271\n",
            "policy/Perplexity                             1.72204\n",
            "policy/dLoss                                  0.00889391\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | Optimizing policy...\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | Computing loss before\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | Computing KL before\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | Optimizing\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | computing loss before\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | computing gradient\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | gradient computed\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | computing descent direction\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | descent direction computed\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | backtrack iters: 2\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | optimization finished\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | Computing KL after\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | Computing loss after\n",
            "2021-02-01 07:09:48 | [trpo_cartpole] epoch #42 | Fitting baseline...\n",
            "2021-02-01 07:09:49 | [trpo_cartpole] epoch #42 | Saving snapshot...\n",
            "2021-02-01 07:09:49 | [trpo_cartpole] epoch #42 | Saved\n",
            "2021-02-01 07:09:49 | [trpo_cartpole] epoch #42 | Time 328.55 s\n",
            "2021-02-01 07:09:49 | [trpo_cartpole] epoch #42 | EpochTime 7.20 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         42\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    379.47\n",
            "LinearFeatureBaseline/ExplainedVariance       0.921263\n",
            "TotalEnvSteps                            177676\n",
            "policy/Entropy                                0.519292\n",
            "policy/KL                                     0.00136097\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.000224696\n",
            "policy/LossBefore                             9.53674e-10\n",
            "policy/Perplexity                             1.68084\n",
            "policy/dLoss                                  0.000224697\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Optimizing policy...\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Computing loss before\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Computing KL before\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Optimizing\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | computing loss before\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | computing gradient\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | gradient computed\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | computing descent direction\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | descent direction computed\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | backtrack iters: 2\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | optimization finished\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Computing KL after\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Computing loss after\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Fitting baseline...\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Saving snapshot...\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Saved\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | Time 336.20 s\n",
            "2021-02-01 07:09:56 | [trpo_cartpole] epoch #43 | EpochTime 7.64 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           98.7083\n",
            "Evaluation/AverageReturn                    474.889\n",
            "Evaluation/Iteration                         43\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        274\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                         71.0249\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    400.39\n",
            "LinearFeatureBaseline/ExplainedVariance       0.843164\n",
            "TotalEnvSteps                            181950\n",
            "policy/Entropy                                0.552491\n",
            "policy/KL                                     0.00766965\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.00419315\n",
            "policy/LossBefore                             0.00796412\n",
            "policy/Perplexity                             1.73758\n",
            "policy/dLoss                                  0.00377096\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Optimizing policy...\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Computing loss before\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Computing KL before\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Optimizing\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | computing loss before\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | computing gradient\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | gradient computed\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | computing descent direction\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | descent direction computed\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | backtrack iters: 2\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | optimization finished\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Computing KL after\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Computing loss after\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Fitting baseline...\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Saving snapshot...\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Saved\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | Time 344.04 s\n",
            "2021-02-01 07:10:04 | [trpo_cartpole] epoch #44 | EpochTime 7.84 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.0209\n",
            "Evaluation/AverageReturn                    481.333\n",
            "Evaluation/Iteration                         44\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        332\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                         52.7973\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    406.87\n",
            "LinearFeatureBaseline/ExplainedVariance       0.906166\n",
            "TotalEnvSteps                            186282\n",
            "policy/Entropy                                0.545195\n",
            "policy/KL                                     0.0060671\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0220947\n",
            "policy/LossBefore                            -0.00617778\n",
            "policy/Perplexity                             1.72494\n",
            "policy/dLoss                                  0.0159169\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | Optimizing policy...\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | Computing loss before\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | Computing KL before\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | Optimizing\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | computing loss before\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | computing gradient\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | gradient computed\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | computing descent direction\n",
            "2021-02-01 07:10:11 | [trpo_cartpole] epoch #45 | descent direction computed\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | backtrack iters: 2\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | optimization finished\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | Computing KL after\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | Computing loss after\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | Fitting baseline...\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | Saving snapshot...\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | Saved\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | Time 351.58 s\n",
            "2021-02-01 07:10:12 | [trpo_cartpole] epoch #45 | EpochTime 7.53 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         45\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    419.77\n",
            "LinearFeatureBaseline/ExplainedVariance       0.989332\n",
            "TotalEnvSteps                            190282\n",
            "policy/Entropy                                0.537894\n",
            "policy/KL                                     0.00882999\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0123103\n",
            "policy/LossBefore                            -3.8147e-09\n",
            "policy/Perplexity                             1.7124\n",
            "policy/dLoss                                  0.0123103\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:10:18 | [trpo_cartpole] epoch #46 | Optimizing policy...\n",
            "2021-02-01 07:10:18 | [trpo_cartpole] epoch #46 | Computing loss before\n",
            "2021-02-01 07:10:18 | [trpo_cartpole] epoch #46 | Computing KL before\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | Optimizing\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | computing loss before\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | computing gradient\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | gradient computed\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | computing descent direction\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | descent direction computed\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | backtrack iters: 7\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | optimization finished\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | Computing KL after\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | Computing loss after\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | Fitting baseline...\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | Saving snapshot...\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | Saved\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | Time 358.67 s\n",
            "2021-02-01 07:10:19 | [trpo_cartpole] epoch #46 | EpochTime 7.08 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         46\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    438.4\n",
            "LinearFeatureBaseline/ExplainedVariance       0.99662\n",
            "TotalEnvSteps                            194282\n",
            "policy/Entropy                                0.523332\n",
            "policy/KL                                     0.000312392\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00022205\n",
            "policy/LossBefore                             1.33514e-08\n",
            "policy/Perplexity                             1.68764\n",
            "policy/dLoss                                  0.000222063\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Optimizing policy...\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Computing loss before\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Computing KL before\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Optimizing\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | computing loss before\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | computing gradient\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | gradient computed\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | computing descent direction\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | descent direction computed\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | backtrack iters: 5\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | optimization finished\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Computing KL after\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Computing loss after\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Fitting baseline...\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Saving snapshot...\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Saved\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | Time 366.15 s\n",
            "2021-02-01 07:10:26 | [trpo_cartpole] epoch #47 | EpochTime 7.47 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         47\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    457.27\n",
            "LinearFeatureBaseline/ExplainedVariance       0.996486\n",
            "TotalEnvSteps                            198282\n",
            "policy/Entropy                                0.51374\n",
            "policy/KL                                     0.0056905\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0052856\n",
            "policy/LossBefore                             5.72205e-09\n",
            "policy/Perplexity                             1.67153\n",
            "policy/dLoss                                  0.00528561\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Optimizing policy...\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Computing loss before\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Computing KL before\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Optimizing\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | computing loss before\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | computing gradient\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | gradient computed\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | computing descent direction\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | descent direction computed\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | backtrack iters: 3\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | optimization finished\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Computing KL after\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Computing loss after\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Fitting baseline...\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Saving snapshot...\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Saved\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | Time 373.34 s\n",
            "2021-02-01 07:10:33 | [trpo_cartpole] epoch #48 | EpochTime 7.18 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         48\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    462.27\n",
            "LinearFeatureBaseline/ExplainedVariance       0.996613\n",
            "TotalEnvSteps                            202282\n",
            "policy/Entropy                                0.519708\n",
            "policy/KL                                     0.00225336\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.000800179\n",
            "policy/LossBefore                            -3.05176e-08\n",
            "policy/Perplexity                             1.68154\n",
            "policy/dLoss                                  0.000800148\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | Optimizing policy...\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | Computing loss before\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | Computing KL before\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | Optimizing\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | computing loss before\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | computing gradient\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | gradient computed\n",
            "2021-02-01 07:10:40 | [trpo_cartpole] epoch #49 | computing descent direction\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | descent direction computed\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | backtrack iters: 0\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | optimization finished\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | Computing KL after\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | Computing loss after\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | Fitting baseline...\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | Saving snapshot...\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | Saved\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | Time 380.60 s\n",
            "2021-02-01 07:10:41 | [trpo_cartpole] epoch #49 | EpochTime 7.25 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         49\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    469.28\n",
            "LinearFeatureBaseline/ExplainedVariance       0.996758\n",
            "TotalEnvSteps                            206282\n",
            "policy/Entropy                                0.539181\n",
            "policy/KL                                     0.00538668\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0070157\n",
            "policy/LossBefore                            -3.8147e-09\n",
            "policy/Perplexity                             1.7146\n",
            "policy/dLoss                                  0.0070157\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Optimizing policy...\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Computing loss before\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Computing KL before\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Optimizing\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | computing loss before\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | computing gradient\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | gradient computed\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | computing descent direction\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | descent direction computed\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | backtrack iters: 3\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | optimization finished\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Computing KL after\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Computing loss after\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Fitting baseline...\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Saving snapshot...\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Saved\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | Time 388.32 s\n",
            "2021-02-01 07:10:48 | [trpo_cartpole] epoch #50 | EpochTime 7.70 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.2427\n",
            "Evaluation/AverageReturn                    490.444\n",
            "Evaluation/Iteration                         50\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        414\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                         27.0272\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    477.29\n",
            "LinearFeatureBaseline/ExplainedVariance       0.934316\n",
            "TotalEnvSteps                            210696\n",
            "policy/Entropy                                0.56151\n",
            "policy/KL                                     0.00512032\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0283582\n",
            "policy/LossBefore                            -0.0242535\n",
            "policy/Perplexity                             1.75332\n",
            "policy/dLoss                                  0.00410467\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | Optimizing policy...\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | Computing loss before\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | Computing KL before\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | Optimizing\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | computing loss before\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | computing gradient\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | gradient computed\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | computing descent direction\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | descent direction computed\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | backtrack iters: 2\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | optimization finished\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | Computing KL after\n",
            "2021-02-01 07:10:55 | [trpo_cartpole] epoch #51 | Computing loss after\n",
            "2021-02-01 07:10:56 | [trpo_cartpole] epoch #51 | Fitting baseline...\n",
            "2021-02-01 07:10:56 | [trpo_cartpole] epoch #51 | Saving snapshot...\n",
            "2021-02-01 07:10:56 | [trpo_cartpole] epoch #51 | Saved\n",
            "2021-02-01 07:10:56 | [trpo_cartpole] epoch #51 | Time 395.56 s\n",
            "2021-02-01 07:10:56 | [trpo_cartpole] epoch #51 | EpochTime 7.23 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         51\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    486.65\n",
            "LinearFeatureBaseline/ExplainedVariance       0.958425\n",
            "TotalEnvSteps                            214696\n",
            "policy/Entropy                                0.536169\n",
            "policy/KL                                     0.00830645\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00473744\n",
            "policy/LossBefore                             1.90735e-09\n",
            "policy/Perplexity                             1.70944\n",
            "policy/dLoss                                  0.00473744\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Optimizing policy...\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Computing loss before\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Computing KL before\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Optimizing\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | computing loss before\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | computing gradient\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | gradient computed\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | computing descent direction\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | descent direction computed\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | backtrack iters: 0\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | optimization finished\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Computing KL after\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Computing loss after\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Fitting baseline...\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Saving snapshot...\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Saved\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | Time 402.71 s\n",
            "2021-02-01 07:11:03 | [trpo_cartpole] epoch #52 | EpochTime 7.15 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         52\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    493.85\n",
            "LinearFeatureBaseline/ExplainedVariance       0.996431\n",
            "TotalEnvSteps                            218696\n",
            "policy/Entropy                                0.541966\n",
            "policy/KL                                     0.00752012\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00302234\n",
            "policy/LossBefore                            -1.90735e-08\n",
            "policy/Perplexity                             1.71938\n",
            "policy/dLoss                                  0.00302232\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Optimizing policy...\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Computing loss before\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Computing KL before\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Optimizing\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | computing loss before\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | computing gradient\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | gradient computed\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | computing descent direction\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | descent direction computed\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | backtrack iters: 2\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | optimization finished\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Computing KL after\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Computing loss after\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Fitting baseline...\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Saving snapshot...\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Saved\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | Time 410.82 s\n",
            "2021-02-01 07:11:11 | [trpo_cartpole] epoch #53 | EpochTime 8.10 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.2699\n",
            "Evaluation/AverageReturn                    492.333\n",
            "Evaluation/Iteration                         53\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        431\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                         21.6846\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    494.51\n",
            "LinearFeatureBaseline/ExplainedVariance       0.959392\n",
            "TotalEnvSteps                            223127\n",
            "policy/Entropy                                0.556797\n",
            "policy/KL                                     0.00670464\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0240877\n",
            "policy/LossBefore                            -0.0140352\n",
            "policy/Perplexity                             1.74507\n",
            "policy/dLoss                                  0.0100525\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Optimizing policy...\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Computing loss before\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Computing KL before\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Optimizing\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Start CG optimization: #parameters: 1282, #inputs: 10, #subsample_inputs: 10\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | computing loss before\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | computing gradient\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | gradient computed\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | computing descent direction\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | descent direction computed\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | backtrack iters: 1\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | optimization finished\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Computing KL after\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Computing loss after\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Fitting baseline...\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Saving snapshot...\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Saved\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | Time 418.29 s\n",
            "2021-02-01 07:11:18 | [trpo_cartpole] epoch #54 | EpochTime 7.46 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           92.6217\n",
            "Evaluation/AverageReturn                    423.2\n",
            "Evaluation/Iteration                         54\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                         72\n",
            "Evaluation/NumEpisodes                       10\n",
            "Evaluation/StdReturn                        154.855\n",
            "Evaluation/TerminationRate                    0.2\n",
            "Extras/EpisodeRewardMean                    486.83\n",
            "LinearFeatureBaseline/ExplainedVariance       0.710941\n",
            "TotalEnvSteps                            227359\n",
            "policy/Entropy                                0.639491\n",
            "policy/KL                                     0.00783818\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0663195\n",
            "policy/LossBefore                            -0.0576969\n",
            "policy/Perplexity                             1.89552\n",
            "policy/dLoss                                  0.00862263\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Optimizing policy...\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Computing loss before\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Computing KL before\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Optimizing\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | computing loss before\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | computing gradient\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | gradient computed\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | computing descent direction\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | descent direction computed\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | backtrack iters: 1\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | optimization finished\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Computing KL after\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Computing loss after\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Fitting baseline...\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Saving snapshot...\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Saved\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | Time 425.45 s\n",
            "2021-02-01 07:11:25 | [trpo_cartpole] epoch #55 | EpochTime 7.15 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         55\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    490.77\n",
            "LinearFeatureBaseline/ExplainedVariance       0.961629\n",
            "TotalEnvSteps                            231359\n",
            "policy/Entropy                                0.505774\n",
            "policy/KL                                     0.00589845\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00403485\n",
            "policy/LossBefore                            -1.90735e-09\n",
            "policy/Perplexity                             1.65827\n",
            "policy/dLoss                                  0.00403485\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Optimizing policy...\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Computing loss before\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Computing KL before\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Optimizing\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | computing loss before\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | computing gradient\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | gradient computed\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | computing descent direction\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | descent direction computed\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | backtrack iters: 1\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | optimization finished\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Computing KL after\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Computing loss after\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Fitting baseline...\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Saving snapshot...\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Saved\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | Time 432.68 s\n",
            "2021-02-01 07:11:33 | [trpo_cartpole] epoch #56 | EpochTime 7.22 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         56\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    490.77\n",
            "LinearFeatureBaseline/ExplainedVariance       0.996464\n",
            "TotalEnvSteps                            235359\n",
            "policy/Entropy                                0.543489\n",
            "policy/KL                                     0.00902367\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0158083\n",
            "policy/LossBefore                             7.62939e-09\n",
            "policy/Perplexity                             1.722\n",
            "policy/dLoss                                  0.0158083\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Optimizing policy...\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Computing loss before\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Computing KL before\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Optimizing\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Start CG optimization: #parameters: 1282, #inputs: 11, #subsample_inputs: 11\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | computing loss before\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | computing gradient\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | gradient computed\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | computing descent direction\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | descent direction computed\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | backtrack iters: 0\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | optimization finished\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Computing KL after\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Computing loss after\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Fitting baseline...\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Saving snapshot...\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Saved\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | Time 440.09 s\n",
            "2021-02-01 07:11:40 | [trpo_cartpole] epoch #57 | EpochTime 7.40 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           92.7301\n",
            "Evaluation/AverageReturn                    386\n",
            "Evaluation/Iteration                         57\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        111\n",
            "Evaluation/NumEpisodes                       11\n",
            "Evaluation/StdReturn                        151.091\n",
            "Evaluation/TerminationRate                    0.454545\n",
            "Extras/EpisodeRewardMean                    478.23\n",
            "LinearFeatureBaseline/ExplainedVariance       0.506379\n",
            "TotalEnvSteps                            239605\n",
            "policy/Entropy                                0.756592\n",
            "policy/KL                                     0.00855149\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.0546147\n",
            "policy/LossBefore                             0.0630489\n",
            "policy/Perplexity                             2.131\n",
            "policy/dLoss                                  0.00843418\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Optimizing policy...\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Computing loss before\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Computing KL before\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Optimizing\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | computing loss before\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | computing gradient\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | gradient computed\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | computing descent direction\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | descent direction computed\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | backtrack iters: 3\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | optimization finished\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Computing KL after\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Computing loss after\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Fitting baseline...\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Saving snapshot...\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Saved\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | Time 447.27 s\n",
            "2021-02-01 07:11:47 | [trpo_cartpole] epoch #58 | EpochTime 7.16 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         58\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    478.23\n",
            "LinearFeatureBaseline/ExplainedVariance       0.962661\n",
            "TotalEnvSteps                            243605\n",
            "policy/Entropy                                0.532838\n",
            "policy/KL                                     0.00625417\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0057867\n",
            "policy/LossBefore                            -7.62939e-09\n",
            "policy/Perplexity                             1.70376\n",
            "policy/dLoss                                  0.00578669\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Optimizing policy...\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Computing loss before\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Computing KL before\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Optimizing\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | computing loss before\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | computing gradient\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | gradient computed\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | computing descent direction\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | descent direction computed\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | backtrack iters: 1\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | optimization finished\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Computing KL after\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Computing loss after\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Fitting baseline...\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Saving snapshot...\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Saved\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | Time 454.45 s\n",
            "2021-02-01 07:11:54 | [trpo_cartpole] epoch #59 | EpochTime 7.17 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         59\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    478.23\n",
            "LinearFeatureBaseline/ExplainedVariance       0.996809\n",
            "TotalEnvSteps                            247605\n",
            "policy/Entropy                                0.526998\n",
            "policy/KL                                     0.00857088\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00604004\n",
            "policy/LossBefore                             1.14441e-08\n",
            "policy/Perplexity                             1.69384\n",
            "policy/dLoss                                  0.00604005\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Optimizing policy...\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Computing loss before\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Computing KL before\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Optimizing\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | computing loss before\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | computing gradient\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | gradient computed\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | computing descent direction\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | descent direction computed\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | backtrack iters: 1\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | optimization finished\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Computing KL after\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Computing loss after\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Fitting baseline...\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Saving snapshot...\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Saved\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | Time 461.67 s\n",
            "2021-02-01 07:12:02 | [trpo_cartpole] epoch #60 | EpochTime 7.21 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         60\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    478.23\n",
            "LinearFeatureBaseline/ExplainedVariance       0.996965\n",
            "TotalEnvSteps                            251605\n",
            "policy/Entropy                                0.548204\n",
            "policy/KL                                     0.00885627\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00800403\n",
            "policy/LossBefore                             2.67029e-08\n",
            "policy/Perplexity                             1.73014\n",
            "policy/dLoss                                  0.00800406\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Optimizing policy...\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Computing loss before\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Computing KL before\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Optimizing\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | computing loss before\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | computing gradient\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | gradient computed\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | computing descent direction\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | descent direction computed\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | backtrack iters: 2\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | optimization finished\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Computing KL after\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Computing loss after\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Fitting baseline...\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Saving snapshot...\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Saved\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | Time 469.48 s\n",
            "2021-02-01 07:12:09 | [trpo_cartpole] epoch #61 | EpochTime 7.80 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.1954\n",
            "Evaluation/AverageReturn                    487.778\n",
            "Evaluation/Iteration                         61\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        390\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                         34.5697\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    477.99\n",
            "LinearFeatureBaseline/ExplainedVariance       0.91822\n",
            "TotalEnvSteps                            255995\n",
            "policy/Entropy                                0.561179\n",
            "policy/KL                                     0.00787392\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0429423\n",
            "policy/LossBefore                            -0.0367822\n",
            "policy/Perplexity                             1.75274\n",
            "policy/dLoss                                  0.00616009\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | Optimizing policy...\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | Computing loss before\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | Computing KL before\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | Optimizing\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | computing loss before\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | computing gradient\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | gradient computed\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | computing descent direction\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | descent direction computed\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | backtrack iters: 0\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | optimization finished\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | Computing KL after\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | Computing loss after\n",
            "2021-02-01 07:12:16 | [trpo_cartpole] epoch #62 | Fitting baseline...\n",
            "2021-02-01 07:12:17 | [trpo_cartpole] epoch #62 | Saving snapshot...\n",
            "2021-02-01 07:12:17 | [trpo_cartpole] epoch #62 | Saved\n",
            "2021-02-01 07:12:17 | [trpo_cartpole] epoch #62 | Time 476.55 s\n",
            "2021-02-01 07:12:17 | [trpo_cartpole] epoch #62 | EpochTime 7.06 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn           91.5209\n",
            "Evaluation/AverageReturn                    448.222\n",
            "Evaluation/Iteration                         62\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                         34\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                        146.45\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    473.33\n",
            "LinearFeatureBaseline/ExplainedVariance       0.899062\n",
            "TotalEnvSteps                            260029\n",
            "policy/Entropy                                0.574842\n",
            "policy/KL                                     0.0095881\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0357274\n",
            "policy/LossBefore                            -0.0231166\n",
            "policy/Perplexity                             1.77685\n",
            "policy/dLoss                                  0.0126109\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | Optimizing policy...\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | Computing loss before\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | Computing KL before\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | Optimizing\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | computing loss before\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | computing gradient\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | gradient computed\n",
            "2021-02-01 07:12:23 | [trpo_cartpole] epoch #63 | computing descent direction\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | descent direction computed\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | backtrack iters: 1\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | optimization finished\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | Computing KL after\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | Computing loss after\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | Fitting baseline...\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | Saving snapshot...\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | Saved\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | Time 483.61 s\n",
            "2021-02-01 07:12:24 | [trpo_cartpole] epoch #63 | EpochTime 7.05 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         63\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    473.33\n",
            "LinearFeatureBaseline/ExplainedVariance       0.986942\n",
            "TotalEnvSteps                            264029\n",
            "policy/Entropy                                0.518435\n",
            "policy/KL                                     0.00894323\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00821758\n",
            "policy/LossBefore                             3.8147e-09\n",
            "policy/Perplexity                             1.6794\n",
            "policy/dLoss                                  0.00821759\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Optimizing policy...\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Computing loss before\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Computing KL before\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Optimizing\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | computing loss before\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | computing gradient\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | gradient computed\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | computing descent direction\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | descent direction computed\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | backtrack iters: 0\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | optimization finished\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Computing KL after\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Computing loss after\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Fitting baseline...\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Saving snapshot...\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Saved\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | Time 490.74 s\n",
            "2021-02-01 07:12:31 | [trpo_cartpole] epoch #64 | EpochTime 7.12 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         64\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    473.33\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997342\n",
            "TotalEnvSteps                            268029\n",
            "policy/Entropy                                0.546863\n",
            "policy/KL                                     0.00736463\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00946535\n",
            "policy/LossBefore                             1.90735e-09\n",
            "policy/Perplexity                             1.72782\n",
            "policy/dLoss                                  0.00946536\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Optimizing policy...\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Computing loss before\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Computing KL before\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Optimizing\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | computing loss before\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | computing gradient\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | gradient computed\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | computing descent direction\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | descent direction computed\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | backtrack iters: 0\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | optimization finished\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Computing KL after\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Computing loss after\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Fitting baseline...\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Saving snapshot...\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Saved\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | Time 497.80 s\n",
            "2021-02-01 07:12:38 | [trpo_cartpole] epoch #65 | EpochTime 7.05 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         65\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    474.02\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997494\n",
            "TotalEnvSteps                            272029\n",
            "policy/Entropy                                0.528449\n",
            "policy/KL                                     0.00644422\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00726099\n",
            "policy/LossBefore                             7.62939e-09\n",
            "policy/Perplexity                             1.6963\n",
            "policy/dLoss                                  0.007261\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Optimizing policy...\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Computing loss before\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Computing KL before\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Optimizing\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | computing loss before\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | computing gradient\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | gradient computed\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | computing descent direction\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | descent direction computed\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | backtrack iters: 2\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | optimization finished\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Computing KL after\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Computing loss after\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Fitting baseline...\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Saving snapshot...\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Saved\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | Time 504.81 s\n",
            "2021-02-01 07:12:45 | [trpo_cartpole] epoch #66 | EpochTime 7.00 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         66\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    481.7\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997445\n",
            "TotalEnvSteps                            276029\n",
            "policy/Entropy                                0.515699\n",
            "policy/KL                                     0.0032532\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00122606\n",
            "policy/LossBefore                            -7.62939e-09\n",
            "policy/Perplexity                             1.67481\n",
            "policy/dLoss                                  0.00122606\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Optimizing policy...\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Computing loss before\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Computing KL before\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Optimizing\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | computing loss before\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | computing gradient\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | gradient computed\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | computing descent direction\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | descent direction computed\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | backtrack iters: 1\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | optimization finished\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Computing KL after\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Computing loss after\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Fitting baseline...\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Saving snapshot...\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Saved\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | Time 512.04 s\n",
            "2021-02-01 07:12:52 | [trpo_cartpole] epoch #67 | EpochTime 7.21 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         67\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    481.7\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997279\n",
            "TotalEnvSteps                            280029\n",
            "policy/Entropy                                0.52804\n",
            "policy/KL                                     0.0076751\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0107106\n",
            "policy/LossBefore                            -1.90735e-09\n",
            "policy/Perplexity                             1.6956\n",
            "policy/dLoss                                  0.0107106\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Optimizing policy...\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Computing loss before\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Computing KL before\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Optimizing\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | computing loss before\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | computing gradient\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | gradient computed\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | computing descent direction\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | descent direction computed\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | backtrack iters: 0\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | optimization finished\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Computing KL after\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Computing loss after\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Fitting baseline...\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Saving snapshot...\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Saved\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | Time 519.21 s\n",
            "2021-02-01 07:12:59 | [trpo_cartpole] epoch #68 | EpochTime 7.17 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         68\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    481.7\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997634\n",
            "TotalEnvSteps                            284029\n",
            "policy/Entropy                                0.481558\n",
            "policy/KL                                     0.00978187\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00507684\n",
            "policy/LossBefore                            -1.19209e-10\n",
            "policy/Perplexity                             1.61859\n",
            "policy/dLoss                                  0.00507684\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | Optimizing policy...\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | Computing loss before\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | Computing KL before\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | Optimizing\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | computing loss before\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | computing gradient\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | gradient computed\n",
            "2021-02-01 07:13:06 | [trpo_cartpole] epoch #69 | computing descent direction\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | descent direction computed\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | backtrack iters: 0\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | optimization finished\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | Computing KL after\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | Computing loss after\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | Fitting baseline...\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | Saving snapshot...\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | Saved\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | Time 526.58 s\n",
            "2021-02-01 07:13:07 | [trpo_cartpole] epoch #69 | EpochTime 7.36 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         69\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    492.61\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997758\n",
            "TotalEnvSteps                            288029\n",
            "policy/Entropy                                0.486478\n",
            "policy/KL                                     0.00725731\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00989159\n",
            "policy/LossBefore                            -8.58307e-09\n",
            "policy/Perplexity                             1.62658\n",
            "policy/dLoss                                  0.00989158\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Optimizing policy...\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Computing loss before\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Computing KL before\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Optimizing\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | computing loss before\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | computing gradient\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | gradient computed\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | computing descent direction\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | descent direction computed\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | backtrack iters: 1\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | optimization finished\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Computing KL after\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Computing loss after\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Fitting baseline...\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Saving snapshot...\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Saved\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | Time 533.73 s\n",
            "2021-02-01 07:13:14 | [trpo_cartpole] epoch #70 | EpochTime 7.14 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         70\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    494.24\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997636\n",
            "TotalEnvSteps                            292029\n",
            "policy/Entropy                                0.535373\n",
            "policy/KL                                     0.00662517\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0110882\n",
            "policy/LossBefore                            -1.00136e-08\n",
            "policy/Perplexity                             1.70809\n",
            "policy/dLoss                                  0.0110882\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Optimizing policy...\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Computing loss before\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Computing KL before\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Optimizing\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | computing loss before\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | computing gradient\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | gradient computed\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | computing descent direction\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | descent direction computed\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | backtrack iters: 0\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | optimization finished\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Computing KL after\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Computing loss after\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Fitting baseline...\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Saving snapshot...\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Saved\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | Time 540.83 s\n",
            "2021-02-01 07:13:21 | [trpo_cartpole] epoch #71 | EpochTime 7.08 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         71\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    494.24\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997646\n",
            "TotalEnvSteps                            296029\n",
            "policy/Entropy                                0.518372\n",
            "policy/KL                                     0.00485825\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00507646\n",
            "policy/LossBefore                             1.04904e-08\n",
            "policy/Perplexity                             1.67929\n",
            "policy/dLoss                                  0.00507647\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Optimizing policy...\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Computing loss before\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Computing KL before\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Optimizing\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | computing loss before\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | computing gradient\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | gradient computed\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | computing descent direction\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | descent direction computed\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | backtrack iters: 5\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | optimization finished\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Computing KL after\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Computing loss after\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Fitting baseline...\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Saving snapshot...\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Saved\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | Time 547.93 s\n",
            "2021-02-01 07:13:28 | [trpo_cartpole] epoch #72 | EpochTime 7.10 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         72\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    494.24\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997673\n",
            "TotalEnvSteps                            300029\n",
            "policy/Entropy                                0.516595\n",
            "policy/KL                                     0.000944179\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.000470755\n",
            "policy/LossBefore                            -1.14441e-08\n",
            "policy/Perplexity                             1.67631\n",
            "policy/dLoss                                  0.000470743\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Optimizing policy...\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Computing loss before\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Computing KL before\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Optimizing\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | computing loss before\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | computing gradient\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | gradient computed\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | computing descent direction\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | descent direction computed\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | backtrack iters: 1\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | optimization finished\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Computing KL after\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Computing loss after\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Fitting baseline...\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Saving snapshot...\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Saved\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | Time 555.01 s\n",
            "2021-02-01 07:13:35 | [trpo_cartpole] epoch #73 | EpochTime 7.06 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         73\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    495.34\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997709\n",
            "TotalEnvSteps                            304029\n",
            "policy/Entropy                                0.488272\n",
            "policy/KL                                     0.00919516\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00987216\n",
            "policy/LossBefore                             5.34058e-08\n",
            "policy/Perplexity                             1.6295\n",
            "policy/dLoss                                  0.00987221\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Optimizing policy...\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Computing loss before\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Computing KL before\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Optimizing\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | computing loss before\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | computing gradient\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | gradient computed\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | computing descent direction\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | descent direction computed\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | backtrack iters: 3\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | optimization finished\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Computing KL after\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Computing loss after\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Fitting baseline...\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Saving snapshot...\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Saved\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | Time 562.05 s\n",
            "2021-02-01 07:13:42 | [trpo_cartpole] epoch #74 | EpochTime 7.03 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         74\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    495.34\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997747\n",
            "TotalEnvSteps                            308029\n",
            "policy/Entropy                                0.513705\n",
            "policy/KL                                     0.00584109\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.004736\n",
            "policy/LossBefore                            -0\n",
            "policy/Perplexity                             1.67147\n",
            "policy/dLoss                                  0.004736\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Optimizing policy...\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Computing loss before\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Computing KL before\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Optimizing\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | computing loss before\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | computing gradient\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | gradient computed\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | computing descent direction\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | descent direction computed\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | backtrack iters: 0\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | optimization finished\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Computing KL after\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Computing loss after\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Fitting baseline...\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Saving snapshot...\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Saved\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | Time 569.31 s\n",
            "2021-02-01 07:13:49 | [trpo_cartpole] epoch #75 | EpochTime 7.25 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         75\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997579\n",
            "TotalEnvSteps                            312029\n",
            "policy/Entropy                                0.50953\n",
            "policy/KL                                     0.00842276\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0130583\n",
            "policy/LossBefore                             2.47955e-08\n",
            "policy/Perplexity                             1.66451\n",
            "policy/dLoss                                  0.0130584\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | Optimizing policy...\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | Computing loss before\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | Computing KL before\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | Optimizing\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | computing loss before\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | computing gradient\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | gradient computed\n",
            "2021-02-01 07:13:56 | [trpo_cartpole] epoch #76 | computing descent direction\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | descent direction computed\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | backtrack iters: 1\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | optimization finished\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | Computing KL after\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | Computing loss after\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | Fitting baseline...\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | Saving snapshot...\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | Saved\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | Time 576.60 s\n",
            "2021-02-01 07:13:57 | [trpo_cartpole] epoch #76 | EpochTime 7.27 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         76\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997631\n",
            "TotalEnvSteps                            316029\n",
            "policy/Entropy                                0.46706\n",
            "policy/KL                                     0.00837405\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0078512\n",
            "policy/LossBefore                            -1.33514e-08\n",
            "policy/Perplexity                             1.5953\n",
            "policy/dLoss                                  0.00785118\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Optimizing policy...\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Computing loss before\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Computing KL before\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Optimizing\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | computing loss before\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | computing gradient\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | gradient computed\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | computing descent direction\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | descent direction computed\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | backtrack iters: 0\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | optimization finished\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Computing KL after\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Computing loss after\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Fitting baseline...\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Saving snapshot...\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Saved\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | Time 583.85 s\n",
            "2021-02-01 07:14:04 | [trpo_cartpole] epoch #77 | EpochTime 7.24 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         77\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997665\n",
            "TotalEnvSteps                            320029\n",
            "policy/Entropy                                0.49424\n",
            "policy/KL                                     0.00836444\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0137093\n",
            "policy/LossBefore                            -1.90735e-09\n",
            "policy/Perplexity                             1.63925\n",
            "policy/dLoss                                  0.0137093\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Optimizing policy...\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Computing loss before\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Computing KL before\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Optimizing\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | computing loss before\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | computing gradient\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | gradient computed\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | computing descent direction\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | descent direction computed\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | backtrack iters: 1\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | optimization finished\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Computing KL after\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Computing loss after\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Fitting baseline...\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Saving snapshot...\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Saved\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | Time 591.03 s\n",
            "2021-02-01 07:14:11 | [trpo_cartpole] epoch #78 | EpochTime 7.17 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         78\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997661\n",
            "TotalEnvSteps                            324029\n",
            "policy/Entropy                                0.491642\n",
            "policy/KL                                     0.00535372\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00604633\n",
            "policy/LossBefore                             9.53674e-09\n",
            "policy/Perplexity                             1.635\n",
            "policy/dLoss                                  0.00604634\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Optimizing policy...\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Computing loss before\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Computing KL before\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Optimizing\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | computing loss before\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | computing gradient\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | gradient computed\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | computing descent direction\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | descent direction computed\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | backtrack iters: 0\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | optimization finished\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Computing KL after\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Computing loss after\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Fitting baseline...\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Saving snapshot...\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Saved\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | Time 598.16 s\n",
            "2021-02-01 07:14:18 | [trpo_cartpole] epoch #79 | EpochTime 7.12 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         79\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.998107\n",
            "TotalEnvSteps                            328029\n",
            "policy/Entropy                                0.475779\n",
            "policy/KL                                     0.00664165\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00228997\n",
            "policy/LossBefore                             2.47955e-08\n",
            "policy/Perplexity                             1.60927\n",
            "policy/dLoss                                  0.00229\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Optimizing policy...\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Computing loss before\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Computing KL before\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Optimizing\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | computing loss before\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | computing gradient\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | gradient computed\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | computing descent direction\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | descent direction computed\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | backtrack iters: 0\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | optimization finished\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Computing KL after\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Computing loss after\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Fitting baseline...\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Saving snapshot...\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Saved\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | Time 605.17 s\n",
            "2021-02-01 07:14:25 | [trpo_cartpole] epoch #80 | EpochTime 7.00 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         80\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.99775\n",
            "TotalEnvSteps                            332029\n",
            "policy/Entropy                                0.457447\n",
            "policy/KL                                     0.00947953\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00282298\n",
            "policy/LossBefore                             1.90735e-09\n",
            "policy/Perplexity                             1.58003\n",
            "policy/dLoss                                  0.00282298\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Optimizing policy...\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Computing loss before\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Computing KL before\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Optimizing\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | computing loss before\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | computing gradient\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | gradient computed\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | computing descent direction\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | descent direction computed\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | backtrack iters: 0\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | optimization finished\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Computing KL after\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Computing loss after\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Fitting baseline...\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Saving snapshot...\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Saved\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | Time 612.48 s\n",
            "2021-02-01 07:14:32 | [trpo_cartpole] epoch #81 | EpochTime 7.30 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         81\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.99759\n",
            "TotalEnvSteps                            336029\n",
            "policy/Entropy                                0.476489\n",
            "policy/KL                                     0.00483048\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0086924\n",
            "policy/LossBefore                            -7.62939e-09\n",
            "policy/Perplexity                             1.61041\n",
            "policy/dLoss                                  0.00869239\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Optimizing policy...\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Computing loss before\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Computing KL before\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Optimizing\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | computing loss before\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | computing gradient\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | gradient computed\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | computing descent direction\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | descent direction computed\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | backtrack iters: 0\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | optimization finished\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Computing KL after\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Computing loss after\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Fitting baseline...\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Saving snapshot...\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Saved\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | Time 619.75 s\n",
            "2021-02-01 07:14:40 | [trpo_cartpole] epoch #82 | EpochTime 7.26 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         82\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997894\n",
            "TotalEnvSteps                            340029\n",
            "policy/Entropy                                0.474817\n",
            "policy/KL                                     0.0078233\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0130922\n",
            "policy/LossBefore                             8.58307e-09\n",
            "policy/Perplexity                             1.60772\n",
            "policy/dLoss                                  0.0130922\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Optimizing policy...\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Computing loss before\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Computing KL before\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Optimizing\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | computing loss before\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | computing gradient\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | gradient computed\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | computing descent direction\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | descent direction computed\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | backtrack iters: 1\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | optimization finished\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Computing KL after\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Computing loss after\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Fitting baseline...\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Saving snapshot...\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Saved\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | Time 626.92 s\n",
            "2021-02-01 07:14:47 | [trpo_cartpole] epoch #83 | EpochTime 7.16 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         83\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997409\n",
            "TotalEnvSteps                            344029\n",
            "policy/Entropy                                0.473676\n",
            "policy/KL                                     0.00912019\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00595199\n",
            "policy/LossBefore                            -9.53674e-10\n",
            "policy/Perplexity                             1.60589\n",
            "policy/dLoss                                  0.00595199\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Optimizing policy...\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Computing loss before\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Computing KL before\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Optimizing\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | computing loss before\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | computing gradient\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | gradient computed\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | computing descent direction\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | descent direction computed\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | backtrack iters: 0\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | optimization finished\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Computing KL after\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Computing loss after\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Fitting baseline...\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Saving snapshot...\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Saved\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | Time 634.03 s\n",
            "2021-02-01 07:14:54 | [trpo_cartpole] epoch #84 | EpochTime 7.10 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         84\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997979\n",
            "TotalEnvSteps                            348029\n",
            "policy/Entropy                                0.479428\n",
            "policy/KL                                     0.00566258\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00845256\n",
            "policy/LossBefore                             5.72205e-09\n",
            "policy/Perplexity                             1.61515\n",
            "policy/dLoss                                  0.00845257\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Optimizing policy...\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Computing loss before\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Computing KL before\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Optimizing\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | computing loss before\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | computing gradient\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | gradient computed\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | computing descent direction\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | descent direction computed\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | backtrack iters: 0\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | optimization finished\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Computing KL after\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Computing loss after\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Fitting baseline...\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Saving snapshot...\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Saved\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | Time 641.16 s\n",
            "2021-02-01 07:15:01 | [trpo_cartpole] epoch #85 | EpochTime 7.13 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         85\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.998214\n",
            "TotalEnvSteps                            352029\n",
            "policy/Entropy                                0.497683\n",
            "policy/KL                                     0.00493183\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00337777\n",
            "policy/LossBefore                            -2.86102e-09\n",
            "policy/Perplexity                             1.64491\n",
            "policy/dLoss                                  0.00337777\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Optimizing policy...\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Computing loss before\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Computing KL before\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Optimizing\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | computing loss before\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | computing gradient\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | gradient computed\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | computing descent direction\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | descent direction computed\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | backtrack iters: 0\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | optimization finished\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Computing KL after\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Computing loss after\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Fitting baseline...\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Saving snapshot...\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Saved\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | Time 648.44 s\n",
            "2021-02-01 07:15:08 | [trpo_cartpole] epoch #86 | EpochTime 7.27 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         86\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997714\n",
            "TotalEnvSteps                            356029\n",
            "policy/Entropy                                0.480707\n",
            "policy/KL                                     0.00496368\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00272428\n",
            "policy/LossBefore                             7.62939e-09\n",
            "policy/Perplexity                             1.61722\n",
            "policy/dLoss                                  0.00272429\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Optimizing policy...\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Computing loss before\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Computing KL before\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Optimizing\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | computing loss before\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | computing gradient\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | gradient computed\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | computing descent direction\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | descent direction computed\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | backtrack iters: 0\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | optimization finished\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Computing KL after\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Computing loss after\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Fitting baseline...\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Saving snapshot...\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Saved\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | Time 655.46 s\n",
            "2021-02-01 07:15:15 | [trpo_cartpole] epoch #87 | EpochTime 7.01 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         87\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997193\n",
            "TotalEnvSteps                            360029\n",
            "policy/Entropy                                0.451085\n",
            "policy/KL                                     0.00798706\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0112649\n",
            "policy/LossBefore                            -1.43051e-09\n",
            "policy/Perplexity                             1.57002\n",
            "policy/dLoss                                  0.0112649\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Optimizing policy...\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Computing loss before\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Computing KL before\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Optimizing\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | computing loss before\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | computing gradient\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | gradient computed\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | computing descent direction\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | descent direction computed\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | backtrack iters: 0\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | optimization finished\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Computing KL after\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Computing loss after\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Fitting baseline...\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Saving snapshot...\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Saved\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | Time 662.50 s\n",
            "2021-02-01 07:15:22 | [trpo_cartpole] epoch #88 | EpochTime 7.04 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         88\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997568\n",
            "TotalEnvSteps                            364029\n",
            "policy/Entropy                                0.487394\n",
            "policy/KL                                     0.00653215\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00797763\n",
            "policy/LossBefore                             3.33786e-09\n",
            "policy/Perplexity                             1.62807\n",
            "policy/dLoss                                  0.00797764\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Optimizing policy...\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Computing loss before\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Computing KL before\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Optimizing\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | computing loss before\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | computing gradient\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | gradient computed\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | computing descent direction\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | descent direction computed\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | backtrack iters: 0\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | optimization finished\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Computing KL after\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Computing loss after\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Fitting baseline...\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Saving snapshot...\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Saved\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | Time 669.73 s\n",
            "2021-02-01 07:15:30 | [trpo_cartpole] epoch #89 | EpochTime 7.22 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         89\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.99765\n",
            "TotalEnvSteps                            368029\n",
            "policy/Entropy                                0.459323\n",
            "policy/KL                                     0.00759077\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0102142\n",
            "policy/LossBefore                            -1.90735e-08\n",
            "policy/Perplexity                             1.583\n",
            "policy/dLoss                                  0.0102142\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Optimizing policy...\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Computing loss before\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Computing KL before\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Optimizing\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | computing loss before\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | computing gradient\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | gradient computed\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | computing descent direction\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | descent direction computed\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | backtrack iters: 0\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | optimization finished\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Computing KL after\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Computing loss after\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Fitting baseline...\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Saving snapshot...\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Saved\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | Time 676.95 s\n",
            "2021-02-01 07:15:37 | [trpo_cartpole] epoch #90 | EpochTime 7.22 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         90\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997959\n",
            "TotalEnvSteps                            372029\n",
            "policy/Entropy                                0.480568\n",
            "policy/KL                                     0.00597261\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00570302\n",
            "policy/LossBefore                            -2.47955e-08\n",
            "policy/Perplexity                             1.61699\n",
            "policy/dLoss                                  0.005703\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Optimizing policy...\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Computing loss before\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Computing KL before\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Optimizing\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | computing loss before\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | computing gradient\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | gradient computed\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | computing descent direction\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | descent direction computed\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | backtrack iters: 0\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | optimization finished\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Computing KL after\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Computing loss after\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Fitting baseline...\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Saving snapshot...\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Saved\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | Time 684.14 s\n",
            "2021-02-01 07:15:44 | [trpo_cartpole] epoch #91 | EpochTime 7.16 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         91\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.99795\n",
            "TotalEnvSteps                            376029\n",
            "policy/Entropy                                0.449334\n",
            "policy/KL                                     0.00872211\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00922267\n",
            "policy/LossBefore                            -1.90735e-09\n",
            "policy/Perplexity                             1.56727\n",
            "policy/dLoss                                  0.00922266\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Optimizing policy...\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Computing loss before\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Computing KL before\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Optimizing\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | computing loss before\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | computing gradient\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | gradient computed\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | computing descent direction\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | descent direction computed\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | backtrack iters: 0\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | optimization finished\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Computing KL after\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Computing loss after\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Fitting baseline...\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Saving snapshot...\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Saved\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | Time 691.16 s\n",
            "2021-02-01 07:15:51 | [trpo_cartpole] epoch #92 | EpochTime 7.01 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         92\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997922\n",
            "TotalEnvSteps                            380029\n",
            "policy/Entropy                                0.488555\n",
            "policy/KL                                     0.00563432\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00921483\n",
            "policy/LossBefore                            -6.4373e-09\n",
            "policy/Perplexity                             1.62996\n",
            "policy/dLoss                                  0.00921482\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Optimizing policy...\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Computing loss before\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Computing KL before\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Optimizing\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | computing loss before\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | computing gradient\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | gradient computed\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | computing descent direction\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | descent direction computed\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | backtrack iters: 0\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | optimization finished\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Computing KL after\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Computing loss after\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Fitting baseline...\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Saving snapshot...\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Saved\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | Time 698.37 s\n",
            "2021-02-01 07:15:58 | [trpo_cartpole] epoch #93 | EpochTime 7.20 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         93\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    500\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997381\n",
            "TotalEnvSteps                            384029\n",
            "policy/Entropy                                0.469189\n",
            "policy/KL                                     0.00661413\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00843244\n",
            "policy/LossBefore                             6.67572e-09\n",
            "policy/Perplexity                             1.5987\n",
            "policy/dLoss                                  0.00843245\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Optimizing policy...\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Computing loss before\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Computing KL before\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Optimizing\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Start CG optimization: #parameters: 1282, #inputs: 12, #subsample_inputs: 12\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | computing loss before\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | computing gradient\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | gradient computed\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | computing descent direction\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | descent direction computed\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | backtrack iters: 1\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | optimization finished\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Computing KL after\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Computing loss after\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Fitting baseline...\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Saving snapshot...\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Saved\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | Time 705.96 s\n",
            "2021-02-01 07:16:06 | [trpo_cartpole] epoch #94 | EpochTime 7.57 s\n",
            "---------------------------------------  ---------------\n",
            "Evaluation/AverageDiscountedReturn           75.2695\n",
            "Evaluation/AverageReturn                    345.583\n",
            "Evaluation/Iteration                         94\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                         14\n",
            "Evaluation/NumEpisodes                       12\n",
            "Evaluation/StdReturn                        219.302\n",
            "Evaluation/TerminationRate                    0.333333\n",
            "Extras/EpisodeRewardMean                    481.47\n",
            "LinearFeatureBaseline/ExplainedVariance       0.714225\n",
            "TotalEnvSteps                            388176\n",
            "policy/Entropy                                0.457126\n",
            "policy/KL                                     0.00822383\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                              0.00895634\n",
            "policy/LossBefore                             0.0178766\n",
            "policy/Perplexity                             1.57953\n",
            "policy/dLoss                                  0.00892021\n",
            "---------------------------------------  ---------------\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Optimizing policy...\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Computing loss before\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Computing KL before\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Optimizing\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | computing loss before\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | computing gradient\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | gradient computed\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | computing descent direction\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | descent direction computed\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | backtrack iters: 0\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | optimization finished\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Computing KL after\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Computing loss after\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Fitting baseline...\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Saving snapshot...\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Saved\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | Time 713.15 s\n",
            "2021-02-01 07:16:13 | [trpo_cartpole] epoch #95 | EpochTime 7.18 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         95\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    481.47\n",
            "LinearFeatureBaseline/ExplainedVariance       0.955476\n",
            "TotalEnvSteps                            392176\n",
            "policy/Entropy                                0.459816\n",
            "policy/KL                                     0.00869244\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00887035\n",
            "policy/LossBefore                            -1.90735e-09\n",
            "policy/Perplexity                             1.58378\n",
            "policy/dLoss                                  0.00887035\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Optimizing policy...\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Computing loss before\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Computing KL before\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Optimizing\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | computing loss before\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | computing gradient\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | gradient computed\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | computing descent direction\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | descent direction computed\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | backtrack iters: 0\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | optimization finished\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Computing KL after\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Computing loss after\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Fitting baseline...\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Saving snapshot...\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Saved\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | Time 720.13 s\n",
            "2021-02-01 07:16:20 | [trpo_cartpole] epoch #96 | EpochTime 6.97 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         96\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    481.47\n",
            "LinearFeatureBaseline/ExplainedVariance       0.9979\n",
            "TotalEnvSteps                            396176\n",
            "policy/Entropy                                0.451576\n",
            "policy/KL                                     0.00938204\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0128242\n",
            "policy/LossBefore                             5.72205e-09\n",
            "policy/Perplexity                             1.57079\n",
            "policy/dLoss                                  0.0128242\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Optimizing policy...\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Computing loss before\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Computing KL before\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Optimizing\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Start CG optimization: #parameters: 1282, #inputs: 8, #subsample_inputs: 8\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | computing loss before\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | computing gradient\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | gradient computed\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | computing descent direction\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | descent direction computed\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | backtrack iters: 2\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | optimization finished\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Computing KL after\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Computing loss after\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Fitting baseline...\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Saving snapshot...\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Saved\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | Time 727.29 s\n",
            "2021-02-01 07:16:27 | [trpo_cartpole] epoch #97 | EpochTime 7.15 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.343\n",
            "Evaluation/AverageReturn                    500\n",
            "Evaluation/Iteration                         97\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        500\n",
            "Evaluation/NumEpisodes                        8\n",
            "Evaluation/StdReturn                          0\n",
            "Evaluation/TerminationRate                    0\n",
            "Extras/EpisodeRewardMean                    481.47\n",
            "LinearFeatureBaseline/ExplainedVariance       0.997745\n",
            "TotalEnvSteps                            400176\n",
            "policy/Entropy                                0.486975\n",
            "policy/KL                                     0.00680014\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.012155\n",
            "policy/LossBefore                            -4.76837e-09\n",
            "policy/Perplexity                             1.62739\n",
            "policy/dLoss                                  0.012155\n",
            "---------------------------------------  ----------------\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Optimizing policy...\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Computing loss before\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Computing KL before\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Optimizing\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Start CG optimization: #parameters: 1282, #inputs: 11, #subsample_inputs: 11\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | computing loss before\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | computing gradient\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | gradient computed\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | computing descent direction\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | descent direction computed\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | backtrack iters: 2\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | optimization finished\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Computing KL after\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Computing loss after\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Fitting baseline...\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Saving snapshot...\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Saved\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | Time 735.28 s\n",
            "2021-02-01 07:16:35 | [trpo_cartpole] epoch #98 | EpochTime 7.98 s\n",
            "---------------------------------------  --------------\n",
            "Evaluation/AverageDiscountedReturn           91.4603\n",
            "Evaluation/AverageReturn                    407.818\n",
            "Evaluation/Iteration                         98\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                         80\n",
            "Evaluation/NumEpisodes                       11\n",
            "Evaluation/StdReturn                        160.677\n",
            "Evaluation/TerminationRate                    0.272727\n",
            "Extras/EpisodeRewardMean                    471.33\n",
            "LinearFeatureBaseline/ExplainedVariance       0.655076\n",
            "TotalEnvSteps                            404662\n",
            "policy/Entropy                                0.485813\n",
            "policy/KL                                     0.0083106\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.0240694\n",
            "policy/LossBefore                            -0.0131794\n",
            "policy/Perplexity                             1.6255\n",
            "policy/dLoss                                  0.01089\n",
            "---------------------------------------  --------------\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Optimizing policy...\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Computing loss before\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Computing KL before\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Optimizing\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Start CG optimization: #parameters: 1282, #inputs: 9, #subsample_inputs: 9\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | computing loss before\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | computing gradient\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | gradient computed\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | computing descent direction\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | descent direction computed\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | backtrack iters: 0\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | optimization finished\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Computing KL after\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Computing loss after\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Fitting baseline...\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Saving snapshot...\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Saved\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | Time 743.25 s\n",
            "2021-02-01 07:16:43 | [trpo_cartpole] epoch #99 | EpochTime 7.96 s\n",
            "---------------------------------------  ----------------\n",
            "Evaluation/AverageDiscountedReturn           99.3415\n",
            "Evaluation/AverageReturn                    499.778\n",
            "Evaluation/Iteration                         99\n",
            "Evaluation/MaxReturn                        500\n",
            "Evaluation/MinReturn                        498\n",
            "Evaluation/NumEpisodes                        9\n",
            "Evaluation/StdReturn                          0.628539\n",
            "Evaluation/TerminationRate                    0.111111\n",
            "Extras/EpisodeRewardMean                    471.31\n",
            "LinearFeatureBaseline/ExplainedVariance       0.948414\n",
            "TotalEnvSteps                            409160\n",
            "policy/Entropy                                0.473552\n",
            "policy/KL                                     0.00934455\n",
            "policy/KLBefore                               0\n",
            "policy/LossAfter                             -0.00653167\n",
            "policy/LossBefore                             0.000614394\n",
            "policy/Perplexity                             1.60569\n",
            "policy/dLoss                                  0.00714606\n",
            "---------------------------------------  ----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NoSuchDisplayException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchDisplayException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8e368b340ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrpo_cartpole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/garage/src/garage/experiment/experiment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mctxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2f2f38ce1a99>\u001b[0m in \u001b[0;36mtrpo_cartpole\u001b[0;34m(ctxt, seed)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/garage/src/garage/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, batch_size, plot, store_episodes, pause_for_plot)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0maverage_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_algo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maverage_return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/src/garage/trainer.py\u001b[0m in \u001b[0;36m_shutdown_worker\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;34m\"\"\"Shutdown Plotter and Sampler workers.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/src/garage/sampler/local_sampler.py\u001b[0m in \u001b[0;36mshutdown_worker\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;34m\"\"\"Shutdown the workers.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mworker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/src/garage/tf/samplers/worker.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m\"\"\"Perform shutdown processes for TF.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_entered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_entered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/src/garage/sampler/default_worker.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;34m\"\"\"Close the worker's environment.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/garage/src/garage/envs/gym_env.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;34m\"\"\"Close the wrapped env.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_viewer_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/src/garage/envs/gym_env.py\u001b[0m in \u001b[0;36m_close_viewer_window\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m                      for package in KNOWN_GYM_NOT_CLOSE_VIEWER):\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'viewer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     from gym.envs.classic_control.rendering import (\n\u001b[0m\u001b[1;32m    329\u001b[0m                         Viewer, SimpleImageViewer)\n\u001b[1;32m    330\u001b[0m                     if (isinstance(self._env.viewer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     raise ImportError('''\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;31m# trickery is for circular import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0m_pyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pyglet_doc_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m     \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m     \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_shadow_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0m_shadow_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0m_shadow_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_can_detect_autorepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/canvas/__init__.py\u001b[0m in \u001b[0;36mget_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Otherwise, create a new display and return it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/canvas/xlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, x_screen)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXOpenDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDisplayException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot connect to \"%s\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mscreen_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXScreenCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchDisplayException\u001b[0m: Cannot connect to \"None\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFm7WbTJZjD9"
      },
      "source": [
        "* TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "replicating_result_CityLearn_MARISA_paper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gliBAt-tsq8X"
      },
      "source": [
        "# Reproducing the result of a single central agent on the CityLearn simulator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNwp47WktT4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6178f864-7d37-423b-a6f6-87cbe627e093"
      },
      "source": [
        "# get CityLearn from github\n",
        "!rm -rf ./CityLearn/\n",
        "!git clone https://github.com/intelligent-environments-lab/CityLearn.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CityLearn'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 783 (delta 10), reused 27 (delta 2), pack-reused 736\u001b[K\n",
            "Receiving objects: 100% (783/783), 36.62 MiB | 21.88 MiB/s, done.\n",
            "Resolving deltas: 100% (439/439), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPNiikjCv2jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1c6b22-787c-4cb0-fdb5-1811939826ef"
      },
      "source": [
        "!pip install stable_baselines3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stable_baselines3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/7c/ec89fd9a51c2ff640f150479069be817136c02f02349b5dd27a6e3bb8b3d/stable_baselines3-0.10.0-py3-none-any.whl (145kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 20kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 30kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 40kB 21.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 51kB 19.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 61kB 15.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 71kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 81kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 92kB 15.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 102kB 15.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 112kB 15.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 122kB 15.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 133kB 15.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 143kB 15.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable_baselines3) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.6/dist-packages (from stable_baselines3) (0.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable_baselines3) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable_baselines3) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from stable_baselines3) (1.7.0+cu101)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17->stable_baselines3) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.17->stable_baselines3) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable_baselines3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->stable_baselines3) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable_baselines3) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable_baselines3) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable_baselines3) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable_baselines3) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable_baselines3) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->stable_baselines3) (1.15.0)\n",
            "Installing collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZImUrqweaF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7318919-062d-4228-f11a-4d9af00ab401"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ls /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7krgx2Ssuwt"
      },
      "source": [
        "# Loading libraries\n",
        "import sys\n",
        "sys.path.append(\"./CityLearn\")\n",
        "\n",
        "from citylearn import CityLearn\n",
        "from reward_function import reward_function_ma\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from agent import RL_Agents_Coord\n",
        "\n",
        "import os\n",
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.sac.policies import MlpPolicy as MlpPolicy_SAC\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSBe1UXIsu3N"
      },
      "source": [
        "# Load environment\n",
        "climate_zone = 4\n",
        "data_path = Path(\"./CityLearn/data/Climate_Zone_\"+str(climate_zone))\n",
        "building_attributes = data_path / 'building_attributes.json'\n",
        "weather_file = data_path / 'weather_data.csv'\n",
        "solar_profile = data_path / 'solar_generation_1kW.csv'\n",
        "building_state_actions = './CityLearn/buildings_state_action_space.json'\n",
        "building_ids = [\"Building_1\",\"Building_2\",\"Building_3\",\"Building_4\",\"Building_5\",\"Building_6\",\"Building_7\",\"Building_8\",\"Building_9\"]\n",
        "objective_function = ['ramping','1-load_factor','average_daily_peak','peak_demand','net_electricity_consumption']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj3jI-W7z0YZ"
      },
      "source": [
        "## Multiple agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uql5sq07svu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7178a1-a365-4022-e83d-5604a063f34e"
      },
      "source": [
        "# Contain the lower and upper bounds of the states and actions, to be provided to the agent to normalize the variables between 0 and 1.\n",
        "# Can be obtained using observations_spaces[i].low or .high\n",
        "env = CityLearn(data_path, \n",
        "                building_attributes, \n",
        "                weather_file, \n",
        "                solar_profile, \n",
        "                building_ids, \n",
        "                buildings_states_actions = building_state_actions, \n",
        "                cost_function = objective_function, \n",
        "                verbose = 0, \n",
        "                simulation_period=(0,8760-1), \n",
        "                central_agent=False)\n",
        "observations_spaces, actions_spaces = env.get_state_action_spaces()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./CityLearn/citylearn.py:527: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  self.state = np.array(self.state)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6733neMsv1F"
      },
      "source": [
        "# Provides information on Building type, Climate Zone, Annual DHW demand, Annual Cooling Demand, Annual Electricity Demand, Solar Capacity, and correllations among buildings\n",
        "building_info = env.get_building_information()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooNGN_J7sv6Y"
      },
      "source": [
        "# Hyperparameters\n",
        "bs = 256\n",
        "tau = 0.005\n",
        "gamma = 0.99\n",
        "lr = 0.0003\n",
        "hid = [256,256]\n",
        "\n",
        "n_episodes = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stzu7PCIswAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea4f486-bae6-4720-e385-0741ea825131"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Instantiating the control agent(s)\n",
        "agents = RL_Agents_Coord(building_ids, \n",
        "                         building_state_actions, \n",
        "                         building_info, \n",
        "                         observations_spaces, \n",
        "                         actions_spaces, \n",
        "                         discount = gamma, \n",
        "                         batch_size = bs, \n",
        "                         replay_buffer_capacity = 1e5, \n",
        "                         regression_buffer_capacity = 12*8760, \n",
        "                         tau=tau, \n",
        "                         lr=lr, \n",
        "                         hidden_dim=hid, \n",
        "                         start_training=8760*3, \n",
        "                         exploration_period = 8760*3+1,  \n",
        "                         start_regression=8760, \n",
        "                         information_sharing = False, # I changed here experimentally. \n",
        "                         pca_compression = .95, \n",
        "                         action_scaling_coef=0.5, \n",
        "                         reward_scaling = 5., \n",
        "                         update_per_step = 1, \n",
        "                         iterations_as = 2)\n",
        "\n",
        "cost_by_epoch = []\n",
        "# The number of episodes can be replaces by a stopping criterion (i.e. convergence of the average reward)\n",
        "start = time.time()\n",
        "for e in range(n_episodes): \n",
        "    is_evaluating = (e > 7) # Evaluate deterministic policy after 7 epochs\n",
        "    rewards = []\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    j = 0\n",
        "    action, coordination_vars = agents.select_action(state, deterministic=is_evaluating)    \n",
        "    while not done:\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        action_next, coordination_vars_next = agents.select_action(next_state, deterministic=is_evaluating)\n",
        "        agents.add_to_buffer(state, action, reward, next_state, done, coordination_vars, coordination_vars_next)\n",
        "\n",
        "        state = next_state\n",
        "        coordination_vars = coordination_vars_next\n",
        "        action = action_next\n",
        "\n",
        "    cost = env.cost()\n",
        "    cost_by_epoch.append(cost)\n",
        "    print('Loss -', cost, 'Simulation time (min) -',(time.time()-start)/60.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss - {'ramping': 1.1929684, '1-load_factor': 1.1250790754531381, 'average_daily_peak': 1.0954074, 'peak_demand': 1.1740308, 'net_electricity_consumption': 1.0374093, 'total': 1.1249789794201566} Simulation time (min) - 0.30750746726989747\n",
            "Loss - {'ramping': 1.1937909, '1-load_factor': 1.108593114277481, 'average_daily_peak': 1.0990715, 'peak_demand': 1.2124575, 'net_electricity_consumption': 1.0370535, 'total': 1.1301933066170928} Simulation time (min) - 0.848811407883962\n",
            "Loss - {'ramping': 1.1920284, '1-load_factor': 1.0958920520026365, 'average_daily_peak': 1.0836817, 'peak_demand': 1.2347693, 'net_electricity_consumption': 1.0371234, 'total': 1.1286989887849266} Simulation time (min) - 2.0703074097633363\n",
            "Loss - {'ramping': 0.8590052, '1-load_factor': 1.018247733312952, 'average_daily_peak': 0.9775157, 'peak_demand': 1.2033315, 'net_electricity_consumption': 1.0018773, 'total': 1.0119954843914722} Simulation time (min) - 25.1030006925265\n",
            "Loss - {'ramping': 0.7939093, '1-load_factor': 0.9240903198894663, 'average_daily_peak': 0.87130195, 'peak_demand': 1.0705855, 'net_electricity_consumption': 0.99536526, 'total': 0.9310504663025698} Simulation time (min) - 48.28785591125488\n",
            "Loss - {'ramping': 0.78156406, '1-load_factor': 0.9142754649766229, 'average_daily_peak': 0.8679441, 'peak_demand': 1.0634596, 'net_electricity_consumption': 0.9974265, 'total': 0.9249339575697568} Simulation time (min) - 71.23434667189916\n",
            "Loss - {'ramping': 0.78041756, '1-load_factor': 0.912456591685705, 'average_daily_peak': 0.8601728, 'peak_demand': 1.0658216, 'net_electricity_consumption': 0.9959256, 'total': 0.9229588428656446} Simulation time (min) - 93.48346238533655\n",
            "Loss - {'ramping': 0.78421783, '1-load_factor': 0.8924713610264482, 'average_daily_peak': 0.86357933, 'peak_demand': 0.97625756, 'net_electricity_consumption': 0.9941227, 'total': 0.9021297549933756} Simulation time (min) - 116.11764296690623\n",
            "Loss - {'ramping': 0.6586721, '1-load_factor': 0.8877121962579064, 'average_daily_peak': 0.8541236, 'peak_demand': 1.0038267, 'net_electricity_consumption': 0.98923695, 'total': 0.8787143142515813} Simulation time (min) - 138.91859331528346\n",
            "Loss - {'ramping': 0.6610228, '1-load_factor': 0.8978124431816936, 'average_daily_peak': 0.8576109, 'peak_demand': 0.9448544, 'net_electricity_consumption': 0.9869959, 'total': 0.8696592722743393} Simulation time (min) - 161.93967793385187\n",
            "Loss - {'ramping': 0.6642873, '1-load_factor': 0.8987988662287737, 'average_daily_peak': 0.8586722, 'peak_demand': 0.94940764, 'net_electricity_consumption': 0.98490936, 'total': 0.8712150778684048} Simulation time (min) - 185.04060096740722\n",
            "Loss - {'ramping': 0.65718347, '1-load_factor': 0.9109145341042687, 'average_daily_peak': 0.8561854, 'peak_demand': 0.9522024, 'net_electricity_consumption': 0.9838647, 'total': 0.872070096685966} Simulation time (min) - 208.09833909273146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLOs6pEuGz1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f227f5a-24c5-4897-a574-5ea820a2a0ba"
      },
      "source": [
        "cost_by_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'1-load_factor': 1.1250790754531381,\n",
              "  'average_daily_peak': 1.0954074,\n",
              "  'net_electricity_consumption': 1.0374093,\n",
              "  'peak_demand': 1.1740308,\n",
              "  'ramping': 1.1929684,\n",
              "  'total': 1.1249789794201566},\n",
              " {'1-load_factor': 1.108593114277481,\n",
              "  'average_daily_peak': 1.0990715,\n",
              "  'net_electricity_consumption': 1.0370535,\n",
              "  'peak_demand': 1.2124575,\n",
              "  'ramping': 1.1937909,\n",
              "  'total': 1.1301933066170928},\n",
              " {'1-load_factor': 1.0958920520026365,\n",
              "  'average_daily_peak': 1.0836817,\n",
              "  'net_electricity_consumption': 1.0371234,\n",
              "  'peak_demand': 1.2347693,\n",
              "  'ramping': 1.1920284,\n",
              "  'total': 1.1286989887849266},\n",
              " {'1-load_factor': 1.018247733312952,\n",
              "  'average_daily_peak': 0.9775157,\n",
              "  'net_electricity_consumption': 1.0018773,\n",
              "  'peak_demand': 1.2033315,\n",
              "  'ramping': 0.8590052,\n",
              "  'total': 1.0119954843914722},\n",
              " {'1-load_factor': 0.9240903198894663,\n",
              "  'average_daily_peak': 0.87130195,\n",
              "  'net_electricity_consumption': 0.99536526,\n",
              "  'peak_demand': 1.0705855,\n",
              "  'ramping': 0.7939093,\n",
              "  'total': 0.9310504663025698},\n",
              " {'1-load_factor': 0.9142754649766229,\n",
              "  'average_daily_peak': 0.8679441,\n",
              "  'net_electricity_consumption': 0.9974265,\n",
              "  'peak_demand': 1.0634596,\n",
              "  'ramping': 0.78156406,\n",
              "  'total': 0.9249339575697568},\n",
              " {'1-load_factor': 0.912456591685705,\n",
              "  'average_daily_peak': 0.8601728,\n",
              "  'net_electricity_consumption': 0.9959256,\n",
              "  'peak_demand': 1.0658216,\n",
              "  'ramping': 0.78041756,\n",
              "  'total': 0.9229588428656446},\n",
              " {'1-load_factor': 0.8924713610264482,\n",
              "  'average_daily_peak': 0.86357933,\n",
              "  'net_electricity_consumption': 0.9941227,\n",
              "  'peak_demand': 0.97625756,\n",
              "  'ramping': 0.78421783,\n",
              "  'total': 0.9021297549933756},\n",
              " {'1-load_factor': 0.8877121962579064,\n",
              "  'average_daily_peak': 0.8541236,\n",
              "  'net_electricity_consumption': 0.98923695,\n",
              "  'peak_demand': 1.0038267,\n",
              "  'ramping': 0.6586721,\n",
              "  'total': 0.8787143142515813},\n",
              " {'1-load_factor': 0.8978124431816936,\n",
              "  'average_daily_peak': 0.8576109,\n",
              "  'net_electricity_consumption': 0.9869959,\n",
              "  'peak_demand': 0.9448544,\n",
              "  'ramping': 0.6610228,\n",
              "  'total': 0.8696592722743393},\n",
              " {'1-load_factor': 0.8987988662287737,\n",
              "  'average_daily_peak': 0.8586722,\n",
              "  'net_electricity_consumption': 0.98490936,\n",
              "  'peak_demand': 0.94940764,\n",
              "  'ramping': 0.6642873,\n",
              "  'total': 0.8712150778684048},\n",
              " {'1-load_factor': 0.9109145341042687,\n",
              "  'average_daily_peak': 0.8561854,\n",
              "  'net_electricity_consumption': 0.9838647,\n",
              "  'peak_demand': 0.9522024,\n",
              "  'ramping': 0.65718347,\n",
              "  'total': 0.872070096685966}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-zS4pDqHAZd"
      },
      "source": [
        "import pickle\n",
        "with open(\"/gdrive/My Drive/cost_by_epoch_cz4.pkl\", \"wb\") as f:\n",
        "    pickle.dump(cost_by_epoch, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgYkYE_nswFa"
      },
      "source": [
        "##Multiple Agent with $r^3$ reward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3CQr-UrlP4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1a16b8-a003-4fb0-f2c2-461664604885"
      },
      "source": [
        "# confirm whetehr reward function is r^3 or not.\n",
        "import inspect\n",
        "lines = inspect.getsource(reward_function_ma)\n",
        "print(lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class reward_function_ma:\n",
            "    def __init__(self, n_agents, building_info):\n",
            "        self.n_agents = n_agents\n",
            "        self.building_info = building_info\n",
            "\n",
            "    # Electricity_demand contains negative values when the building consumes more electricity than it generates\n",
            "    def get_rewards(self, electricity_demand):  \n",
            "        #electricity_demand = np.float32(electricity_demand)\n",
            "        #total_electricity_demand = 0\n",
            "        #for e in electricity_demand:\n",
            "        #    total_electricity_demand += -e\n",
            "            \n",
            "        #electricity_demand = np.array(electricity_demand)\n",
            "        \n",
            "        #return list(np.sign(electricity_demand)*0.01*(np.array(np.abs(electricity_demand))**2 * max(0, total_electricity_demand)))\n",
            "        \n",
            "        # Single-agent reward\n",
            "        reward_ = np.array(electricity_demand)**3.0\n",
            "        reward_[reward_>0] = 0\n",
            "        return list(reward_)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGyzSmw5swKy"
      },
      "source": [
        "# Load environment\n",
        "climate_zone = 4\n",
        "data_path = Path(\"./CityLearn/data/Climate_Zone_\"+str(climate_zone))\n",
        "building_attributes = data_path / 'building_attributes.json'\n",
        "weather_file = data_path / 'weather_data.csv'\n",
        "solar_profile = data_path / 'solar_generation_1kW.csv'\n",
        "building_state_actions = './CityLearn/buildings_state_action_space.json'\n",
        "building_ids = [\"Building_1\",\"Building_2\",\"Building_3\",\"Building_4\",\"Building_5\",\"Building_6\",\"Building_7\",\"Building_8\",\"Building_9\"]\n",
        "objective_function = ['ramping','1-load_factor','average_daily_peak','peak_demand','net_electricity_consumption']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRM_tzwzjEj-"
      },
      "source": [
        "# Contain the lower and upper bounds of the states and actions, to be provided to the agent to normalize the variables between 0 and 1.\n",
        "# Can be obtained using observations_spaces[i].low or .high\n",
        "env = CityLearn(data_path, \n",
        "                building_attributes, \n",
        "                weather_file, \n",
        "                solar_profile, \n",
        "                building_ids, \n",
        "                buildings_states_actions = building_state_actions, \n",
        "                cost_function = objective_function, \n",
        "                verbose = 0, \n",
        "                simulation_period=(0,8760-1), \n",
        "                central_agent=False)\n",
        "observations_spaces, actions_spaces = env.get_state_action_spaces()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnp6OPktswPx"
      },
      "source": [
        "# # Provides information on Building type, Climate Zone, Annual DHW demand, Annual Cooling Demand, Annual Electricity Demand, Solar Capacity, and correllations among buildings\n",
        "building_info = env.get_building_information()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SPo4ozg3aqq"
      },
      "source": [
        "# Hyperparameters\n",
        "bs = 256\n",
        "tau = 0.005\n",
        "gamma = 0.99\n",
        "lr = 0.0003\n",
        "hid = [256,256]\n",
        "\n",
        "n_episodes = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mL-vQvvmJCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad168470-5d94-42c0-95f3-c456503aa794"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Instantiating the control agent(s)\n",
        "agents = RL_Agents_Coord(building_ids, \n",
        "                         building_state_actions, \n",
        "                         building_info, \n",
        "                         observations_spaces, \n",
        "                         actions_spaces, \n",
        "                         discount = gamma, \n",
        "                         batch_size = bs, \n",
        "                         replay_buffer_capacity = 1e5, \n",
        "                         regression_buffer_capacity = 12*8760, \n",
        "                         tau=tau, \n",
        "                         lr=lr, \n",
        "                         hidden_dim=hid, \n",
        "                         start_training=8760*3, \n",
        "                         exploration_period = 8760*3+1,  \n",
        "                         start_regression=8760, \n",
        "                         information_sharing = False, # I changed here experimentally. \n",
        "                         pca_compression = .95, \n",
        "                         action_scaling_coef=0.5, \n",
        "                         reward_scaling = 5., \n",
        "                         update_per_step = 1, \n",
        "                         iterations_as = 2)\n",
        "\n",
        "cost_by_epoch = []\n",
        "# The number of episodes can be replaces by a stopping criterion (i.e. convergence of the average reward)\n",
        "start = time.time()\n",
        "for e in range(n_episodes): \n",
        "    is_evaluating = (e > 7) # Evaluate deterministic policy after 7 epochs\n",
        "    rewards = []\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    j = 0\n",
        "    action, coordination_vars = agents.select_action(state, deterministic=is_evaluating)    \n",
        "    while not done:\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        action_next, coordination_vars_next = agents.select_action(next_state, deterministic=is_evaluating)\n",
        "        agents.add_to_buffer(state, action, reward, next_state, done, coordination_vars, coordination_vars_next)\n",
        "\n",
        "        state = next_state\n",
        "        coordination_vars = coordination_vars_next\n",
        "        action = action_next\n",
        "\n",
        "    cost = env.cost()\n",
        "    cost_by_epoch.append(cost)\n",
        "    print('Loss -', cost, 'Simulation time (min) -',(time.time()-start)/60.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss - {'ramping': 1.1826104, '1-load_factor': 1.1163685108538957, 'average_daily_peak': 1.0879441, 'peak_demand': 1.2307191, 'net_electricity_consumption': 1.0370967, 'total': 1.1309477763437528} Simulation time (min) - 0.2943402926127116\n",
            "Loss - {'ramping': 1.1815282, '1-load_factor': 1.1123980838999392, 'average_daily_peak': 1.0900203, 'peak_demand': 1.2342972, 'net_electricity_consumption': 1.0368078, 'total': 1.1310103050658156} Simulation time (min) - 0.8308295607566833\n",
            "Loss - {'ramping': 1.1819001, '1-load_factor': 1.0967719192027132, 'average_daily_peak': 1.0869675, 'peak_demand': 1.1123391, 'net_electricity_consumption': 1.0372785, 'total': 1.1030514406108674} Simulation time (min) - 2.084572994709015\n",
            "Loss - {'ramping': 0.8548236, '1-load_factor': 1.045004621681809, 'average_daily_peak': 0.99767196, 'peak_demand': 1.1908945, 'net_electricity_consumption': 1.0028597, 'total': 1.018250873791623} Simulation time (min) - 21.59046080907186\n",
            "Loss - {'ramping': 0.8125561, '1-load_factor': 0.9803545867388211, 'average_daily_peak': 0.9121499, 'peak_demand': 1.1552826, 'net_electricity_consumption': 0.997329, 'total': 0.9715344388283246} Simulation time (min) - 40.98255285819371\n",
            "Loss - {'ramping': 0.75915045, '1-load_factor': 0.9502285918192263, 'average_daily_peak': 0.88725984, 'peak_demand': 1.0689683, 'net_electricity_consumption': 0.9975183, 'total': 0.9326250950613855} Simulation time (min) - 60.55898241996765\n",
            "Loss - {'ramping': 0.76452196, '1-load_factor': 0.9224975414478827, 'average_daily_peak': 0.88729376, 'peak_demand': 1.0107173, 'net_electricity_consumption': 0.99684274, 'total': 0.9163746537249098} Simulation time (min) - 80.05622775952021\n",
            "Loss - {'ramping': 0.7797209, '1-load_factor': 0.9525422543961792, 'average_daily_peak': 0.89095205, 'peak_demand': 1.0061479, 'net_electricity_consumption': 0.99581337, 'total': 0.9250352877513366} Simulation time (min) - 99.8303854862849\n",
            "Loss - {'ramping': 0.6775232, '1-load_factor': 0.9331076826315606, 'average_daily_peak': 0.8818851, 'peak_demand': 0.98249066, 'net_electricity_consumption': 0.99100536, 'total': 0.8932024019094603} Simulation time (min) - 120.16193027496338\n",
            "Loss - {'ramping': 0.677696, '1-load_factor': 0.9353543768568416, 'average_daily_peak': 0.8801377, 'peak_demand': 0.9727644, 'net_electricity_consumption': 0.9901696, 'total': 0.8912244012006834} Simulation time (min) - 140.9056867400805\n",
            "Loss - {'ramping': 0.66837543, '1-load_factor': 0.9323232428596342, 'average_daily_peak': 0.8756565, 'peak_demand': 0.9817991, 'net_electricity_consumption': 0.98914474, 'total': 0.8894598058137481} Simulation time (min) - 161.07369374434154\n",
            "Loss - {'ramping': 0.6662668, '1-load_factor': 0.9286189681169168, 'average_daily_peak': 0.8719315, 'peak_demand': 0.95529693, 'net_electricity_consumption': 0.9877465, 'total': 0.8819721342300728} Simulation time (min) - 181.1403041402499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MklSyqAP6nfE"
      },
      "source": [
        "# # Plotting winter operation\n",
        "# interval = range(5000,5200)\n",
        "# plt.figure(figsize=(16,5))\n",
        "# plt.plot(env.net_electric_consumption_no_pv_no_storage[interval])\n",
        "# plt.plot(env.net_electric_consumption_no_storage[interval])\n",
        "# plt.plot(env.net_electric_consumption[interval], '--')\n",
        "# plt.xlabel('time (hours)')\n",
        "# plt.ylabel('kW')\n",
        "# plt.legend(['Electricity demand without storage or generation (kW)', \n",
        "#             'Electricity demand with PV generation and without storage(kW)', \n",
        "#             'Electricity demand with PV generation and using SAC for storage(kW)'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySwc8yeCswtL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDDd9SIHswxa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOe1p-Fpsw2W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwxD7gyTsw7E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjMebrfOsw_k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwjuUzGEsxEO"
      },
      "source": [
        "## Appendix:\n",
        "* Climate zone 4: without information sharing\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/56372825/107677087-dc657500-6c67-11eb-95b1-017fb426fb6a.png)\n",
        "\n",
        "* Climate zone 4: without information sharing and reward = $r^3$\n",
        "    * So, in this case, the agents are independent with each other. One difference from the single central agent is the input state (observation) dimention. \n",
        "    * multiagent non info sharing $r^33$: $26 \\times (PCA dim reduction rate)$ for each policy network (there is 9 policy network) \n",
        "    * single central agent $81$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ViqRsf_sxId"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQpfnk76sxM4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgR-JacCsxRO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggDnpi9jsu8z"
      },
      "source": [
        ""
      ]
    }
  ]
}
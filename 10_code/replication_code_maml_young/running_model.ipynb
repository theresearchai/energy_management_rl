{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"running_model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMiBainJGfvZU5+K0458fUz"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3PqOZPlhrx8","executionInfo":{"status":"ok","timestamp":1614294700560,"user_tz":300,"elapsed":25113,"user":{"displayName":"Young Kyung Kim","photoUrl":"","userId":"04144196223982995614"}},"outputId":"5b538c03-81bf-41e4-df9c-3fc494edda61"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","!ls /gdrive\n","\n","# Set the right directory\n","# Must change to right directory to run!\n","%cd /gdrive/My\\ Drive/Colab\\ Notebooks/RL/pytorch-maml-rl"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n","MyDrive\n","/gdrive/My Drive/Colab Notebooks/RL/pytorch-maml-rl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bXMy05k3lbIf","executionInfo":{"status":"ok","timestamp":1614294715032,"user_tz":300,"elapsed":14463,"user":{"displayName":"Young Kyung Kim","photoUrl":"","userId":"04144196223982995614"}}},"source":["import random\n","\n","import maml_rl.envs\n","import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import json\n","\n","from maml_rl.metalearner import MetaLearner, KPolicyMetaLearner, total_rewards\n","from maml_rl.policies import CategoricalMLPPolicy, NormalMLPPolicy\n","from maml_rl.baseline import LinearFeatureBaseline\n","from maml_rl.sampler import BatchSampler\n","# from maml_rl.utils.helpers import get_policy_for_env, get_input_size\n","# from maml_rl.utils.reinforcement_learning import get_returns"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wdSCVjprxXI","executionInfo":{"status":"ok","timestamp":1614294885731,"user_tz":300,"elapsed":414,"user":{"displayName":"Young Kyung Kim","photoUrl":"","userId":"04144196223982995614"}}},"source":["# def to_numpy(tensor):\n","#     if isinstance(tensor, torch.Tensor):\n","#         return tensor.detach().cpu().numpy()\n","#     elif isinstance(tensor, np.ndarray):\n","#         return tensor\n","#     elif isinstance(tensor, (tuple, list)):\n","#         return np.stack([to_numpy(t) for t in tensor], axis=0)\n","#     else:\n","#         raise NotImplementedError()\n","# # def get_returns(episodes):\n","#     return to_numpy([episode.rewards().sum(dim=0) for episode in episodes])\n","def get_returns(episodes):\n","  return ([np.array(episodes._rewards_list).sum()])\n","    # return ([np.array(episodes._rewards_list).sum() for episode in episodes])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQmOJ8YUh6l1","executionInfo":{"status":"ok","timestamp":1614296158009,"user_tz":300,"elapsed":1270017,"user":{"displayName":"Young Kyung Kim","photoUrl":"","userId":"04144196223982995614"}},"outputId":"8dac6616-38dc-4bd8-98ee-49aec8d88d71"},"source":["'''\n","training cell\n","'''\n","# set parameter\n","env_name = \"2DNavigationBiased-v0\"\n","# env_name ='HalfCheetahVel-v1'\n","batch_size = 20 \n","num_workers = 8\n","seed = 11\n","hidden_size = 50\n","num_layer = 2\n","gamma = 0.99\n","tau = 1.0\n","lr = 0.1\n","device = torch.device('cuda')\n","num_batches = 50\n","meta_policy_num = 2\n","meta_batch_size = 10\n","first_order = False\n","max_kl = 0.01\n","cg_iters = 10\n","cg_damping = 1e-5\n","ls_max_steps = 15\n","ls_backtrack_ratio = 0.8\n","\n","policy_filename = \"saved_policy\"\n","\n","# to keep track\n","logs_exp = {'tasks': []}\n","train_returns_exp, valid_returns_exp = [], []\n","train_episodes_exp, valid_episodes_exp = [], []\n","\n","# set sampler\n","sampler = BatchSampler(env_name, batch_size=batch_size,\\\n","                       num_workers=num_workers, seed=seed)\n","\n","# set policy (This is for continuous action space)\n","policy = NormalMLPPolicy(int(np.prod(sampler.envs.observation_space.shape)),\\\n","    int(np.prod(sampler.envs.action_space.shape)),\\\n","    hidden_sizes=(hidden_size,) * num_layer)\n","\n","# set baseline\n","baseline = LinearFeatureBaseline(int(np.prod(sampler.envs.observation_space.shape)))\n","\n","# set metalearner\n","\n","metalearner = MetaLearner(sampler, policy, baseline, gamma=gamma,\\\n","                          fast_lr=lr, tau=tau, device=device)\n","# num_batches = 10\n","for batch in range(meta_policy_num * num_batches):\n","  print (batch)\n","  # first sample tasks under the distribution\n","  tasks = sampler.sample_tasks(num_tasks=meta_batch_size)\n","  # get episodes in the form of (train episodes, test episodes after adaption)\n","  episodes = metalearner.sample(tasks, first_order=first_order)\n","  metalearner.step(episodes, max_kl=max_kl, cg_iters=cg_iters,\\\n","                   cg_damping=cg_damping, ls_max_steps=ls_max_steps,\\\n","                   ls_backtrack_ratio=ls_backtrack_ratio)\n","  if batch < 10:\n","    train_returns_exp.append(get_returns(episodes[0][0]))\n","    # for i in range(len(episodes)):\n","    #   train_episodes_exp.append(episodes[i][0])\n","    #   valid_episodes_exp.append(episodes[i][1])\n","    logs_exp['tasks'].extend(tasks)\n","    # train_returns_exp.append(get_returns(episodes[i][0]))\n","    # valid_returns_exp.append(get_returns(episodes[i][1]))\n","  # # Tensorboard\n","  # writer.add_scalar('maml/before_update',\\\n","  #                   total_rewards([ep.rewards for ep, _ in episodes]), batch)\n","  # writer.add_scalar('maml/after_update',\\\n","  #                   total_rewards([ep.rewards for _, ep in episodes]), batch)\n","\n","# # Save policy network\n","# with open(policy_filename, 'wb') as f:\n","#   torch.save(policy.state_dict(), f)\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"stream","text":["3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LvzF2QfqqT0C","executionInfo":{"status":"ok","timestamp":1614296249793,"user_tz":300,"elapsed":1355218,"user":{"displayName":"Young Kyung Kim","photoUrl":"","userId":"04144196223982995614"}},"outputId":"d612e8cd-2d95-40f4-d2e7-e322ee001399"},"source":["'''\n","test cell\n","'''\n","# policy = NormalMLPPolicy(int(np.prod(sampler.envs.observation_space.shape)),\\\n","#     int(np.prod(sampler.envs.action_space.shape)),\\\n","#     hidden_sizes=(hidden_size,) * num_layer)\n","# with open(policy_filename, 'rb') as f:\n","#         state_dict = torch.load(f, map_location=torch.device(args.device))\n","#         policy.load_state_dict(state_dict)\n","#     policy.share_memory()\n","\n","logs = {'tasks': []}\n","train_returns, valid_returns = [], []\n","train_episodes, valid_episodes = [], []\n","for batch in range(10):\n","  print (batch)\n","  # first sample tasks under the distribution\n","  tasks = sampler.sample_tasks(num_tasks=meta_batch_size)\n","  episodes = metalearner.sample(tasks, first_order=first_order)\n","  # train_episodes.append(episodes[0][0])\n","  # for i in range(len(episodes)):\n","  #   train_episodes.append(episodes[0][0])\n","  #   valid_episodes.append(episodes[i][1])\n","  logs['tasks'].extend(tasks)\n","  train_returns.append(get_returns(episodes[0][0]))\n","  # valid_returns.append(get_returns(valid_episodes))\n","# logs['train_returns'] = np.concatenate(np.mean(train_returns), axis=0)\n","# logs['valid_returns'] = np.concatenate(np.mean(valid_returns)                                                        , axis=0)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n","4\n","5\n","6\n","7\n","8\n","9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ceoy1aWu7fnf","executionInfo":{"status":"ok","timestamp":1614297513819,"user_tz":300,"elapsed":421,"user":{"displayName":"Young Kyung Kim","photoUrl":"","userId":"04144196223982995614"}},"outputId":"24fb151a-bd50-4f87-a090-003aaddc004c"},"source":["# test score\n","# np.mean(train_returns)\n","for i in range(len(train_returns)):\n","  print (sum(train_returns[i])/len(train_returns))\n","# for i in range(len(train_returns_exp)):\n","#   print (sum(train_returns_exp[i])/len(train_returns_exp))\n","# print (type(valid_returns))\n","# print (sum(train_returns)/len(train_returns))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["-213.069189453125\n","-212.85224609375\n","-207.938427734375\n","-217.076806640625\n","-207.89970703125\n","-221.257080078125\n","-223.60625\n","-202.1246337890625\n","-198.1708251953125\n","-236.647021484375\n"],"name":"stdout"}]}]}